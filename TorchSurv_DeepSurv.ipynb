{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1EY87_PKv0dTOF6mK_Kx8YPzRYVzJ6o-8",
      "authorship_tag": "ABX9TyMVv6qU83CXs5f6vB6dPVXn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osun24/nsclc-adj-chemo/blob/main/TorchSurv_DeepSurv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install torchsurv scikit-survival\n",
        "\n",
        "# Import required packages\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsurv.models import MLP\n",
        "from torchsurv.losses import CoxPHLoss\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "\n",
        "# (Optional) Mount Google Drive if you plan to load/save files there\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81TEvMle6mqs",
        "outputId": "26f41926-0850-404c-8a84-b2c6ec5d26b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchsurv\n",
            "  Downloading torchsurv-0.1.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting scikit-survival\n",
            "  Downloading scikit_survival-0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchsurv) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torchsurv) (1.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchsurv) (2.0.2)\n",
            "Collecting torchmetrics (from torchsurv)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting ecos (from scikit-survival)\n",
            "  Downloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (1.4.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (2.10.2)\n",
            "Collecting osqp<1.0.0,>=0.6.3 (from scikit-survival)\n",
            "  Downloading osqp-0.6.7.post3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<1.7,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (1.6.1)\n",
            "Collecting qdldl (from osqp<1.0.0,>=0.6.3->scikit-survival)\n",
            "  Downloading qdldl-0.1.7.post5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->scikit-survival) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->scikit-survival) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->scikit-survival) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.7,>=1.6.1->scikit-survival) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torchsurv)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torchsurv)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torchsurv)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torchsurv)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torchsurv)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torchsurv)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torchsurv)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torchsurv)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torchsurv)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torchsurv)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchsurv) (1.3.0)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics->torchsurv) (24.2)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->torchsurv)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics->torchsurv) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->scikit-survival) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchsurv) (3.0.2)\n",
            "Downloading torchsurv-0.1.4-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_survival-0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading osqp-0.6.7.post3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.3/298.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.1/220.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading qdldl-0.1.7.post5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, qdldl, nvidia-cusparse-cu12, nvidia-cudnn-cu12, ecos, osqp, nvidia-cusolver-cu12, scikit-survival, torchmetrics, torchsurv\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baO87aHV3DUA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsurv.models import MLP\n",
        "from torchsurv.losses import CoxPHLoss\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "\n",
        "# Define a PyTorch Dataset for survival data\n",
        "class SurvivalDataset(Dataset):\n",
        "    def __init__(self, features, time_vals, events):\n",
        "        self.x = torch.tensor(features, dtype=torch.float32)\n",
        "        self.time = torch.tensor(time_vals, dtype=torch.float32)\n",
        "        self.event = torch.tensor(events, dtype=torch.float32)\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.time[idx], self.event[idx]\n",
        "\n",
        "# Training loop for one epoch\n",
        "def train_model(model, criterion, optimizer, dataloader, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for x, time_vals, events in dataloader:\n",
        "        x = x.to(device)\n",
        "        time_vals = time_vals.to(device)\n",
        "        events = events.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass produces log hazard ratios\n",
        "        outputs = model(x)\n",
        "        loss = criterion(outputs, time_vals, events)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "    return running_loss / len(dataloader.dataset)\n",
        "\n",
        "# Evaluation: compute concordance index using sksurv's metric\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_time = []\n",
        "    all_event = []\n",
        "    with torch.no_grad():\n",
        "        for x, time_vals, events in dataloader:\n",
        "            x = x.to(device)\n",
        "            preds = model(x)\n",
        "            all_preds.append(preds.cpu().numpy().flatten())\n",
        "            all_time.append(time_vals.numpy())\n",
        "            all_event.append(events.numpy())\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_time = np.concatenate(all_time)\n",
        "    all_event = np.concatenate(all_event)\n",
        "    # Higher risk scores (log hazard ratios) should correspond to worse outcomes.\n",
        "    ci = concordance_index_censored(all_event.astype(bool), all_time, all_preds)[0]\n",
        "    return ci\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load the Affy datasets from Google Drive\n",
        "    train_df = pd.read_csv(\"/content/drive/MyDrive/affyTrain.csv\")\n",
        "    valid_df = pd.read_csv(\"/content/drive/MyDrive/affyValidation.csv\")\n",
        "\n",
        "    # Process binary columns (if applicable)\n",
        "    binary_columns = ['Adjuvant Chemo', 'IS_MALE']\n",
        "    for col in binary_columns:\n",
        "        if col in train_df.columns:\n",
        "            train_df[col] = train_df[col].astype(int)\n",
        "        if col in valid_df.columns:\n",
        "            valid_df[col] = valid_df[col].astype(int)\n",
        "\n",
        "    # Define survival columns and feature columns\n",
        "    survival_cols = ['OS_STATUS', 'OS_MONTHS']\n",
        "    feature_cols = [col for col in train_df.columns if col not in survival_cols]\n",
        "\n",
        "    X_train = train_df[feature_cols].values.astype(np.float32)\n",
        "    y_train_time = train_df['OS_MONTHS'].values.astype(np.float32)\n",
        "    y_train_event = train_df['OS_STATUS'].values.astype(np.float32)\n",
        "\n",
        "    X_valid = valid_df[feature_cols].values.astype(np.float32)\n",
        "    y_valid_time = valid_df['OS_MONTHS'].values.astype(np.float32)\n",
        "    y_valid_event = valid_df['OS_STATUS'].values.astype(np.float32)\n",
        "\n",
        "    # Create PyTorch datasets and loaders\n",
        "    train_dataset = SurvivalDataset(X_train, y_train_time, y_train_event)\n",
        "    valid_dataset = SurvivalDataset(X_valid, y_valid_time, y_valid_event)\n",
        "\n",
        "    batch_size = 32\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Hyperparameter grid for DeepSurv (MLP) model\n",
        "    hidden_layer_configs = [\n",
        "        [32],\n",
        "        [64],\n",
        "        [32, 16],\n",
        "        [64, 32]\n",
        "    ]\n",
        "    dropout_rates = [0.0, 0.2, 0.5]\n",
        "    learning_rates = [0.001, 0.01]\n",
        "    weight_decays = [0.0, 1e-4, 1e-3]\n",
        "\n",
        "    num_epochs = 100  # epochs per configuration\n",
        "    best_ci = -np.inf\n",
        "    best_hyperparams = None\n",
        "    best_model_state = None\n",
        "    results = []\n",
        "\n",
        "    # Grid search over the hyperparameters\n",
        "    for layers in hidden_layer_configs:\n",
        "        for dropout in dropout_rates:\n",
        "            for lr in learning_rates:\n",
        "                for wd in weight_decays:\n",
        "                    print(f\"Training with layers={layers}, dropout={dropout}, lr={lr}, weight_decay={wd}\")\n",
        "                    # Initialize model as in TorchSurv's DeepSurv example\n",
        "                    model = MLP(in_features=X_train.shape[1], layers=layers, dropout=dropout, activation=torch.relu).to(device)\n",
        "                    criterion = CoxPHLoss()\n",
        "                    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "                    best_epoch_ci = -np.inf\n",
        "                    for epoch in range(num_epochs):\n",
        "                        train_loss = train_model(model, criterion, optimizer, train_loader, device)\n",
        "                        val_ci = evaluate_model(model, valid_loader, device)\n",
        "                        if (epoch + 1) % 10 == 0:\n",
        "                            print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val CI: {val_ci:.4f}\")\n",
        "                        if val_ci > best_epoch_ci:\n",
        "                            best_epoch_ci = val_ci\n",
        "                    results.append({\n",
        "                        'layers': layers,\n",
        "                        'dropout': dropout,\n",
        "                        'learning_rate': lr,\n",
        "                        'weight_decay': wd,\n",
        "                        'val_ci': best_epoch_ci\n",
        "                    })\n",
        "                    print(f\"Finished config: Val CI = {best_epoch_ci:.4f}\\n\")\n",
        "                    if best_epoch_ci > best_ci:\n",
        "                        best_ci = best_epoch_ci\n",
        "                        best_hyperparams = {\n",
        "                            'layers': layers,\n",
        "                            'dropout': dropout,\n",
        "                            'learning_rate': lr,\n",
        "                            'weight_decay': wd\n",
        "                        }\n",
        "                        best_model_state = model.state_dict()\n",
        "\n",
        "    print(\"Best Hyperparameters:\")\n",
        "    print(best_hyperparams)\n",
        "    print(\"Best Validation CI:\", best_ci)\n",
        "\n",
        "    # Save results and best model to Google Drive\n",
        "    current_date = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
        "    output_dir = \"/content/drive/MyDrive/deepsurv_results\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_csv_path = os.path.join(output_dir, f\"{current_date}_deepsurv_hyperparam_search_results.csv\")\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "    print(f\"Hyperparameter search results saved to {results_csv_path}\")\n",
        "\n",
        "    best_model_path = os.path.join(output_dir, f\"{current_date}_best_deepsurv_model.pth\")\n",
        "    torch.save(best_model_state, best_model_path)\n",
        "    print(f\"Best model saved to {best_model_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}