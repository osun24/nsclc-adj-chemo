{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1EY87_PKv0dTOF6mK_Kx8YPzRYVzJ6o-8",
      "authorship_tag": "ABX9TyOZlTv3sT10vUvhAVTZ+ViN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osun24/nsclc-adj-chemo/blob/main/TorchSurv_DeepSurv_with_Optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install torchsurv scikit-survival\n",
        "\n",
        "# Import required packages\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "\n",
        "# (Optional) Mount Google Drive if you plan to load/save files there\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from optuna_dashboard import run_server\n",
        "import threading, time, portpicker\n",
        "from google.colab import output\n",
        "\n",
        "PORT = portpicker.pick_unused_port()\n",
        "\n",
        "def _serve():\n",
        "    run_server(\"sqlite:///deepsurv_optuna.db\", host=\"0.0.0.0\", port=PORT)\n",
        "\n",
        "threading.Thread(target=_serve, daemon=True).start()\n",
        "time.sleep(2)\n",
        "print(\"Dashboard:\", output.eval_js(f\"google.colab.kernel.proxyPort({PORT}, {{'cache': false}})\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81TEvMle6mqs",
        "outputId": "7fb1bbdb-0bc7-4238-bcb4-4376726dd3f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchsurv\n",
            "  Downloading torchsurv-0.1.5-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: scikit-survival in /usr/local/lib/python3.12/dist-packages (0.25.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from torchsurv) (2.8.0+cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torchsurv) (1.16.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchsurv) (2.0.2)\n",
            "Collecting torchmetrics (from torchsurv)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: ecos in /usr/local/lib/python3.12/dist-packages (from scikit-survival) (2.0.14)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from scikit-survival) (1.5.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.12/dist-packages (from scikit-survival) (2.14.1)\n",
            "Requirement already satisfied: osqp<1.0.0,>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from scikit-survival) (0.6.7.post3)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from scikit-survival) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<1.8,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from scikit-survival) (1.6.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.12/dist-packages (from osqp<1.0.0,>=0.6.3->scikit-survival) (0.1.7.post5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->scikit-survival) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->scikit-survival) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->scikit-survival) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8,>=1.6.1->scikit-survival) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->torchsurv) (3.4.0)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics->torchsurv) (25.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->torchsurv)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->scikit-survival) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->torchsurv) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->torchsurv) (3.0.3)\n",
            "Downloading torchsurv-0.1.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, torchsurv\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2 torchsurv-0.1.5\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Colab-ready single cell: DeepSurv + Optuna HPO + Dashboard\n",
        "# - Keeps ONLY requested clinical vars + genes with Prop==1\n",
        "# - Sorts Train/Val by OS_MONTHS/OS_STATUS (desc)\n",
        "# - Standardizes using TRAIN-only (applies to VAL); after HPO\n",
        "#   restandardizes on TRAIN+VAL and evaluates TEST C-index\n",
        "# - Optuna + Successive Halving pruner\n",
        "# - Optuna Dashboard (proxied URL printed)  [fixed run_server args]\n",
        "# - Encodes architectures as strings to avoid Optuna warning\n",
        "# ============================================================\n",
        "\n",
        "# ---------- Installs (Colab) ----------\n",
        "!pip -q install optuna optuna-dashboard scikit-survival portpicker\n",
        "\n",
        "# ---------- (Optional) Mount Google Drive ----------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ---------- Imports ----------\n",
        "import os, math, copy, warnings, random, gc, time, threading\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "\n",
        "# Cox loss: Prefer torchsurv if available; fallback to Efron implementation\n",
        "try:\n",
        "    from torchsurv.loss.cox import neg_partial_log_likelihood\n",
        "    _HAS_TORCHSURV = True\n",
        "except Exception:\n",
        "    _HAS_TORCHSURV = False\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "\n",
        "import optuna\n",
        "from optuna.pruners import SuccessiveHalvingPruner\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"Ties in event time detected; using efron's method to handle ties.\")\n",
        "\n",
        "# Reproducibility\n",
        "torch.manual_seed(0); np.random.seed(0); random.seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ============================================================\n",
        "# Cox loss fallback (Efron) if torchsurv isn't available\n",
        "# ============================================================\n",
        "def _cox_negloglik_efron(pred, event, time):\n",
        "    eta = pred.reshape(-1)\n",
        "    e = event.to(torch.float32).reshape(-1)\n",
        "    t = time.reshape(-1)\n",
        "\n",
        "    order = torch.argsort(t, descending=True)\n",
        "    t = t[order]; e = e[order]; eta = eta[order]\n",
        "    exp_eta = torch.exp(eta)\n",
        "    cum_exp = torch.cumsum(exp_eta, dim=0)\n",
        "\n",
        "    uniq_mask = torch.ones_like(t, dtype=torch.bool)\n",
        "    uniq_mask[1:] = t[1:] != t[:-1]\n",
        "    idxs = torch.nonzero(uniq_mask, as_tuple=False).reshape(-1)\n",
        "    idxs = torch.cat([idxs, torch.tensor([len(t)], device=t.device)])\n",
        "\n",
        "    nll = torch.tensor(0.0, device=t.device)\n",
        "    for k in range(len(idxs)-1):\n",
        "        start, end = idxs[k].item(), idxs[k+1].item()\n",
        "        e_slice = e[start:end]\n",
        "        d = int(e_slice.sum().item())\n",
        "        if d == 0: continue\n",
        "        eta_events = eta[start:end][e_slice.bool()]\n",
        "        exp_events = exp_eta[start:end][e_slice.bool()]\n",
        "        s_eta = eta_events.sum()\n",
        "        risk_sum = cum_exp[end-1]\n",
        "        s_exp = exp_events.sum()\n",
        "        eps = 1e-12\n",
        "        log_terms = 0.0\n",
        "        for j in range(d):\n",
        "            log_terms = log_terms + torch.log(risk_sum - (j / d) * s_exp + eps)\n",
        "        nll = nll - (s_eta - log_terms)\n",
        "    return nll / t.numel()\n",
        "\n",
        "def cox_negloglik(pred, event, time):\n",
        "    if _HAS_TORCHSURV:\n",
        "        return neg_partial_log_likelihood(pred, event, time, reduction='mean')\n",
        "    return _cox_negloglik_efron(pred, event, time)\n",
        "\n",
        "# ============================================================\n",
        "# Model, Dataset, Sampler, Utilities\n",
        "# ============================================================\n",
        "class DeepSurvMLP(nn.Module):\n",
        "    def __init__(self, in_features, hidden_layers, dropout=0.0, activation=nn.ReLU()):\n",
        "        super().__init__()\n",
        "        layers, d = [], in_features\n",
        "        for units in hidden_layers:\n",
        "            layers += [nn.Linear(d, units), activation]\n",
        "            if dropout > 0: layers.append(nn.Dropout(dropout))\n",
        "            d = units\n",
        "        layers.append(nn.Linear(d, 1))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "    def forward(self, x): return self.model(x)\n",
        "\n",
        "class SurvivalDataset(Dataset):\n",
        "    def __init__(self, features, time_vals, events):\n",
        "        self.x = torch.tensor(features, dtype=torch.float32)\n",
        "        self.time = torch.tensor(time_vals, dtype=torch.float32)\n",
        "        self.event = torch.tensor(events.astype(bool), dtype=torch.bool)\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, idx): return self.x[idx], self.time[idx], self.event[idx]\n",
        "\n",
        "class EventBalancedBatchSampler(Sampler):\n",
        "    def __init__(self, events_numpy, batch_size, seed=0):\n",
        "        events = np.asarray(events_numpy).astype(bool)\n",
        "        self.pos_idx = np.where(events)[0]\n",
        "        self.neg_idx = np.where(~events)[0]\n",
        "        assert len(self.pos_idx) > 0, \"No events in training set — cannot balance batches.\"\n",
        "        self.bs = int(batch_size)\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "    def __iter__(self):\n",
        "        pos = self.rng.permutation(self.pos_idx)\n",
        "        neg = self.rng.permutation(self.neg_idx)\n",
        "        n_total = len(pos) + len(neg)\n",
        "        n_batches = math.ceil(n_total / self.bs)\n",
        "        pi = ni = 0\n",
        "        for _ in range(n_batches):\n",
        "            take_pos = 1 if pi < len(pos) else 0\n",
        "            avail_neg = max(0, len(neg) - ni)\n",
        "            take_neg = min(self.bs - take_pos, avail_neg)\n",
        "            need = self.bs - (take_pos + take_neg)\n",
        "            extra_pos = min(need, max(0, len(pos) - (pi + take_pos)))\n",
        "            take_pos += extra_pos\n",
        "            batch = np.concatenate([pos[pi:pi+take_pos], neg[ni:ni+take_neg]])\n",
        "            pi += take_pos; ni += take_neg\n",
        "            if batch.size == 0: break\n",
        "            self.rng.shuffle(batch)\n",
        "            yield batch.tolist()\n",
        "    def __len__(self):\n",
        "        return math.ceil((len(self.pos_idx) + len(self.neg_idx)) / self.bs)\n",
        "\n",
        "def make_optimizer(model, lr, wd):\n",
        "    linears = [m for m in model.modules() if isinstance(m, nn.Linear)]\n",
        "    last_linear = linears[-1] if len(linears) > 0 else None\n",
        "    decay, no_decay = [], []\n",
        "    for name, p in model.named_parameters():\n",
        "        if not p.requires_grad: continue\n",
        "        if name.endswith('bias'):\n",
        "            no_decay.append(p); continue\n",
        "        if (last_linear is not None) and (p is last_linear.weight):\n",
        "            no_decay.append(p); continue\n",
        "        decay.append(p)\n",
        "    param_groups = [{'params': decay, 'weight_decay': wd},\n",
        "                    {'params': no_decay, 'weight_decay': 0.0}]\n",
        "    return optim.AdamW(param_groups, lr=lr)\n",
        "\n",
        "def set_dropout_p(model, p):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Dropout): m.p = float(p)\n",
        "\n",
        "def set_weight_decay(optimizer, wd):\n",
        "    for g in optimizer.param_groups: g['weight_decay'] = float(wd)\n",
        "\n",
        "def l1_penalty_first_layer(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Linear): return m.weight.abs().sum()\n",
        "    return torch.tensor(0.0, device=next(model.parameters()).device)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_ci(model, dataloader, device):\n",
        "    model.eval()\n",
        "    preds, times, events = [], [], []\n",
        "    for x, t, e in dataloader:\n",
        "        y = torch.clamp(model(x.to(device)), -20, 20)\n",
        "        preds.append(y.cpu().numpy().ravel())\n",
        "        times.append(t.numpy()); events.append(e.numpy())\n",
        "    preds = np.concatenate(preds)\n",
        "    times = np.concatenate(times); events = np.concatenate(events)\n",
        "    if np.isnan(preds).any(): return -np.inf\n",
        "    return concordance_index_censored(events.astype(bool), times, preds)[0]\n",
        "\n",
        "def train_one_epoch(model, optimizer, dataloader, device, l1_lambda=0.0, epoch=0, warmup_epochs=20):\n",
        "    model.train()\n",
        "    warm = min(1.0, (epoch + 1) / float(warmup_epochs))\n",
        "    loss_sum, n_seen = 0.0, 0\n",
        "    for x, t, e in dataloader:\n",
        "        if e.sum().item() == 0:  # safety (shouldn't happen with balanced sampler)\n",
        "            continue\n",
        "        x, t, e = x.to(device), t.to(device), e.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        out = torch.clamp(model(x), -20, 20)\n",
        "        loss = cox_negloglik(out, e, t)\n",
        "        if l1_lambda > 0:\n",
        "            loss = loss + (l1_lambda * warm) * l1_penalty_first_layer(model)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "        loss_sum += loss.item() * x.size(0)\n",
        "        n_seen += x.size(0)\n",
        "    return {'avg_loss': loss_sum / max(n_seen, 1), 'warm': warm}\n",
        "\n",
        "def full_risk_set_step(model, optimizer, ds, device, l1_lambda=0.0, warm=1.0):\n",
        "    model.train()\n",
        "    X_all = ds.x.to(device); t_all = ds.time.to(device); e_all = ds.event.to(device)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    out_all = torch.clamp(model(X_all), -20, 20)\n",
        "    loss_full = cox_negloglik(out_all, e_all, t_all)\n",
        "    if l1_lambda > 0:\n",
        "        loss_full = loss_full + (l1_lambda * warm) * l1_penalty_first_layer(model)\n",
        "    loss_full.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "    optimizer.step()\n",
        "    return float(loss_full.detach().cpu().item())\n",
        "\n",
        "# ============================================================\n",
        "# Data loading & preprocessing\n",
        "# ============================================================\n",
        "# Default CSV paths (adjust if needed)\n",
        "TRAIN_CSV = \"/content/drive/MyDrive/affyfRMATrain.csv\"\n",
        "VALID_CSV = \"/content/drive/MyDrive/affyfRMAValidation.csv\"\n",
        "TEST_CSV  = \"/content/drive/MyDrive/affyfRMATest.csv\"\n",
        "\n",
        "# Genes list path (uploaded or Drive)\n",
        "GENES_CSV = \"/mnt/data/Genes.csv\"\n",
        "if not os.path.exists(GENES_CSV):\n",
        "    if os.path.exists(\"/content/Genes.csv\"):\n",
        "        GENES_CSV = \"/content/Genes.csv\"\n",
        "    elif os.path.exists(\"/content/drive/MyDrive/Genes.csv\"):\n",
        "        GENES_CSV = \"/content/drive/MyDrive/Genes.csv\"\n",
        "print(\"Genes.csv path:\", GENES_CSV)\n",
        "\n",
        "# Clinical variables to KEEP (exact names)\n",
        "CLINICAL_VARS = [\n",
        "    \"Adjuvant Chemo\",\"Age\",\"IS_MALE\",\n",
        "    \"Stage_IA\",\"Stage_IB\",\"Stage_II\",\"Stage_III\",\n",
        "    \"Histology_Adenocarcinoma\",\"Histology_Large Cell Carcinoma\",\"Histology_Squamous Cell Carcinoma\",\n",
        "    \"Race_African American\",\"Race_Asian\",\"Race_Caucasian\",\"Race_Native Hawaiian or Other Pacific Islander\",\"Race_Unknown\",\n",
        "    \"Smoked?_No\",\"Smoked?_Unknown\",\"Smoked?_Yes\"\n",
        "]\n",
        "\n",
        "def load_genes_list(genes_csv):\n",
        "    g = pd.read_csv(genes_csv)\n",
        "    if not {\"Gene\",\"Prop\"}.issubset(set(g.columns)):\n",
        "        raise ValueError(f\"Genes.csv must contain 'Gene' and 'Prop' columns. Found: {list(g.columns)}\")\n",
        "    genes = g.loc[g[\"Prop\"] == 1, \"Gene\"].astype(str).tolist()\n",
        "    print(f\"[Genes] Selected {len(genes)} genes with Prop == 1\")\n",
        "    return genes\n",
        "\n",
        "def coerce_survival_cols(df):\n",
        "    # Map to integers {0,1}\n",
        "    if df[\"OS_STATUS\"].dtype == object:\n",
        "        df[\"OS_STATUS\"] = df[\"OS_STATUS\"].replace({\"DECEASED\":1,\"LIVING\":0,\"Dead\":1,\"Alive\":0}).astype(int)\n",
        "    else:\n",
        "        df[\"OS_STATUS\"] = pd.to_numeric(df[\"OS_STATUS\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "    df[\"OS_MONTHS\"] = pd.to_numeric(df[\"OS_MONTHS\"], errors=\"coerce\").fillna(0.0).astype(float)\n",
        "    return df\n",
        "\n",
        "def preprocess_split(df, clinical_vars, gene_names):\n",
        "    if \"Adjuvant Chemo\" in df.columns:\n",
        "        df[\"Adjuvant Chemo\"] = df[\"Adjuvant Chemo\"].replace({\"OBS\":0, \"ACT\":1})\n",
        "    for col in [\"Adjuvant Chemo\",\"IS_MALE\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(int)\n",
        "    df = coerce_survival_cols(df)\n",
        "    keep_cols = [c for c in clinical_vars if c in df.columns] + [g for g in gene_names if g in df.columns]\n",
        "    missing_clin = [c for c in clinical_vars if c not in df.columns]\n",
        "    if missing_clin:\n",
        "        print(f\"[WARN] Missing clinical columns: {missing_clin}\")\n",
        "    if len(keep_cols) == 0:\n",
        "        raise ValueError(\"No feature columns found after filtering clinical+genes.\")\n",
        "    cols = [\"OS_STATUS\",\"OS_MONTHS\"] + keep_cols\n",
        "    return df[cols].copy()\n",
        "\n",
        "# Load CSVs\n",
        "train_raw = pd.read_csv(TRAIN_CSV)\n",
        "valid_raw = pd.read_csv(VALID_CSV)\n",
        "test_raw  = pd.read_csv(TEST_CSV)\n",
        "\n",
        "# Load genes (Prop==1)\n",
        "GENE_LIST = load_genes_list(GENES_CSV)\n",
        "\n",
        "# Reduce to requested columns per split\n",
        "train_df = preprocess_split(train_raw, CLINICAL_VARS, GENE_LIST)\n",
        "valid_df = preprocess_split(valid_raw, CLINICAL_VARS, GENE_LIST)\n",
        "test_df  = preprocess_split(test_raw,  CLINICAL_VARS, GENE_LIST)\n",
        "\n",
        "# Ensure consistent columns across splits (intersection)\n",
        "feat_candidates = [c for c in (CLINICAL_VARS + GENE_LIST)\n",
        "                   if c in train_df.columns and c in valid_df.columns and c in test_df.columns]\n",
        "if len(feat_candidates) == 0:\n",
        "    raise ValueError(\"After filtering, no common features across train/val/test.\")\n",
        "print(f\"[Features] Using {len(feat_candidates)} common features.\")\n",
        "\n",
        "# Sort Train/Val by event time & status (descending)\n",
        "train_df = train_df.sort_values(by=[\"OS_MONTHS\",\"OS_STATUS\"], ascending=[False, False]).reset_index(drop=True)\n",
        "valid_df = valid_df.sort_values(by=[\"OS_MONTHS\",\"OS_STATUS\"], ascending=[False, False]).reset_index(drop=True)\n",
        "\n",
        "# Build arrays & TRAIN-only standardization (apply to VAL)\n",
        "X_train = train_df[feat_candidates].values.astype(np.float32)\n",
        "X_valid = valid_df[feat_candidates].values.astype(np.float32)\n",
        "\n",
        "train_medians = np.nanmedian(X_train, axis=0)\n",
        "X_train = np.where(np.isnan(X_train), train_medians, X_train)\n",
        "X_valid = np.where(np.isnan(X_valid), train_medians, X_valid)\n",
        "\n",
        "scaler_tv = StandardScaler().fit(X_train)\n",
        "X_train = scaler_tv.transform(X_train).astype(np.float32)\n",
        "X_valid = scaler_tv.transform(X_valid).astype(np.float32)\n",
        "\n",
        "ytr_time = train_df[\"OS_MONTHS\"].values.astype(np.float32)\n",
        "ytr_event = train_df[\"OS_STATUS\"].values.astype(int)\n",
        "yva_time = valid_df[\"OS_MONTHS\"].values.astype(np.float32)\n",
        "yva_event = valid_df[\"OS_STATUS\"].values.astype(int)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "train_ds = SurvivalDataset(X_train, ytr_time, ytr_event)\n",
        "valid_ds = SurvivalDataset(X_valid, yva_time, yva_event)\n",
        "\n",
        "train_sampler = EventBalancedBatchSampler(ytr_event, BATCH_SIZE, seed=42)\n",
        "train_loader  = DataLoader(train_ds, batch_sampler=train_sampler, num_workers=0)\n",
        "train_eval_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "valid_loader      = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "in_dim = X_train.shape[1]\n",
        "print(\"Input dim:\", in_dim)\n",
        "\n",
        "# ============================================================\n",
        "# Optuna Objective & Study  (arch encoded as strings -> parsed)\n",
        "# ============================================================# ============================================================\n",
        "# Optuna Objective & Study — Expanded Space to Reduce Overfitting\n",
        "#   * Architectures include smaller, narrower and bottlenecks\n",
        "#   * Stronger regularizers: higher dropout, input dropout, L1/L2\n",
        "#   * Optionally apply WD to final layer\n",
        "#   * Batch size, grad clip, scheduler, epochs per trial\n",
        "#   * Input Gaussian noise\n",
        "# ============================================================\n",
        "\n",
        "# Wider set of architectures (strings -> parsed lists)\n",
        "ARCH_CHOICES = (\n",
        "    # very small\n",
        "    \"16\", \"32\",\n",
        "    # small / medium singles\n",
        "    \"64\", \"128\", \"256\",\n",
        "    # conservative big single\n",
        "    \"512\",\n",
        "    # 2-layer bottlenecks and symmetric\n",
        "    \"32-16\", \"32-32\", \"64-32\", \"64-64\",\n",
        "    \"128-64\", \"128-128\", \"256-128\", \"256-256\",\n",
        "    \"512-256\", \"512-512\",\n",
        "    # 3-layer (narrowing)\n",
        "    \"64-32-16\", \"128-64-32\", \"256-128-64\"\n",
        ")\n",
        "\n",
        "def layers_from_arch(arch_str: str):\n",
        "    return [int(x) for x in arch_str.split(\"-\") if x.strip()]\n",
        "\n",
        "def suggest_hparams(trial):\n",
        "    arch = trial.suggest_categorical(\"arch\", ARCH_CHOICES)\n",
        "\n",
        "    # Regularization knobs\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.10, 0.70)             # ↑ upper bound\n",
        "    input_dropout = trial.suggest_float(\"input_dropout\", 0.00, 0.30) # feature dropout before first layer\n",
        "\n",
        "    # L2 (weight decay): allow much stronger; optionally apply to final layer too\n",
        "    wd = trial.suggest_float(\"wd\", 1e-6, 1e-1, log=True)\n",
        "    apply_final_wd = trial.suggest_categorical(\"apply_final_wd\", (0, 1))\n",
        "\n",
        "    # L1: allow disabling OR stronger values\n",
        "    use_l1 = trial.suggest_categorical(\"use_l1\", (0, 1))\n",
        "    l1 = 0.0 if use_l1 == 0 else trial.suggest_float(\"l1\", 1e-8, 3e-3, log=True)\n",
        "\n",
        "    # Optim & schedule\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 5e-4, log=True)\n",
        "    sched = trial.suggest_categorical(\"sched\", (\"cosine\", \"cawr\", \"none\"))\n",
        "    if sched == \"cawr\":\n",
        "        cawr_T0 = trial.suggest_int(\"cawr_T0\", 16, 80, step=8)\n",
        "        cawr_Tmult = trial.suggest_categorical(\"cawr_Tmult\", (1, 2, 3))\n",
        "    else:\n",
        "        cawr_T0, cawr_Tmult = None, None\n",
        "\n",
        "    # Training controls\n",
        "    epochs = trial.suggest_int(\"epochs\", 64, 512, step=32)           # per-trial budget\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", (32, 64, 128))\n",
        "    grad_clip = trial.suggest_float(\"grad_clip\", 1.0, 10.0)          # stability & regularization\n",
        "\n",
        "    # Data regularization\n",
        "    noise_std = trial.suggest_float(\"noise_std\", 0.0, 0.10)          # Gaussian feature noise\n",
        "\n",
        "    return {\n",
        "        \"arch\": arch,\n",
        "        \"dropout\": dropout,\n",
        "        \"input_dropout\": input_dropout,\n",
        "        \"lr\": lr,\n",
        "        \"wd\": wd,\n",
        "        \"apply_final_wd\": apply_final_wd,\n",
        "        \"l1\": l1,\n",
        "        \"sched\": sched,\n",
        "        \"cawr_T0\": cawr_T0,\n",
        "        \"cawr_Tmult\": cawr_Tmult,\n",
        "        \"epochs\": epochs,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"grad_clip\": grad_clip,\n",
        "        \"noise_std\": noise_std,\n",
        "    }\n",
        "\n",
        "# Warmups (as before)\n",
        "MAX_EPOCHS_CAP = 512  # absolute cap (safety)\n",
        "WARMUP_EPOCHS_L1 = 30\n",
        "WARMUP_EPOCHS_DROPOUT = 30\n",
        "WARMUP_EPOCHS_WD = 30\n",
        "DROPOUT_START = 0.15\n",
        "WD_START = 0.0\n",
        "\n",
        "# Local helpers that add input dropout/noise and variable grad clip\n",
        "def _apply_input_dropout(x, p):\n",
        "    if p <= 0.0: return x\n",
        "    # inverted dropout on features\n",
        "    keep = 1.0 - p\n",
        "    mask = torch.bernoulli(torch.full_like(x, keep))\n",
        "    return x * mask / max(keep, 1e-6)\n",
        "\n",
        "def train_one_epoch_reg(model, optimizer, dataloader, device,\n",
        "                        l1_lambda=0.0, epoch=0, warmup_epochs=20,\n",
        "                        input_dropout=0.0, noise_std=0.0, grad_clip=5.0):\n",
        "    model.train()\n",
        "    warm = min(1.0, (epoch + 1) / float(warmup_epochs))\n",
        "    loss_sum, n_seen = 0.0, 0\n",
        "    for x, t, e in dataloader:\n",
        "        if e.sum().item() == 0:\n",
        "            continue\n",
        "        x, t, e = x.to(device), t.to(device), e.to(device)\n",
        "\n",
        "        # data-level regularization\n",
        "        if input_dropout > 0.0:\n",
        "            x = _apply_input_dropout(x, input_dropout)\n",
        "        if noise_std > 0.0:\n",
        "            x = x + noise_std * torch.randn_like(x)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        out = torch.clamp(model(x), -20, 20)\n",
        "        loss = cox_negloglik(out, e, t)\n",
        "        if l1_lambda > 0:\n",
        "            loss = loss + (l1_lambda * warm) * l1_penalty_first_layer(model)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), float(grad_clip))\n",
        "        optimizer.step()\n",
        "        loss_sum += loss.item() * x.size(0)\n",
        "        n_seen += x.size(0)\n",
        "    return {'avg_loss': loss_sum / max(n_seen, 1), 'warm': warm}\n",
        "\n",
        "def full_risk_set_step_reg(model, optimizer, ds, device,\n",
        "                           l1_lambda=0.0, warm=1.0,\n",
        "                           input_dropout=0.0, noise_std=0.0, grad_clip=5.0):\n",
        "    model.train()\n",
        "    X_all = ds.x.to(device); t_all = ds.time.to(device); e_all = ds.event.to(device)\n",
        "    XX = X_all\n",
        "    if input_dropout > 0.0:\n",
        "        XX = _apply_input_dropout(XX, input_dropout)\n",
        "    if noise_std > 0.0:\n",
        "        XX = XX + noise_std * torch.randn_like(XX)\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    out_all = torch.clamp(model(XX), -20, 20)\n",
        "    loss_full = cox_negloglik(out_all, e_all, t_all)\n",
        "    if l1_lambda > 0:\n",
        "        loss_full = loss_full + (l1_lambda * warm) * l1_penalty_first_layer(model)\n",
        "    loss_full.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), float(grad_clip))\n",
        "    optimizer.step()\n",
        "    return float(loss_full.detach().cpu().item())\n",
        "\n",
        "# Optimizer that can optionally apply WD to the final layer\n",
        "def make_optimizer_hpo(model, lr, wd, apply_final_wd=False):\n",
        "    linears = [m for m in model.modules() if isinstance(m, nn.Linear)]\n",
        "    last_linear = linears[-1] if len(linears) > 0 else None\n",
        "    decay, no_decay = [], []\n",
        "    for name, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        if name.endswith('bias'):\n",
        "            no_decay.append(p); continue\n",
        "        if (last_linear is not None) and (p is last_linear.weight) and not apply_final_wd:\n",
        "            no_decay.append(p); continue\n",
        "        decay.append(p)\n",
        "    param_groups = [{'params': decay, 'weight_decay': float(wd)},\n",
        "                    {'params': no_decay, 'weight_decay': 0.0}]\n",
        "    return optim.AdamW(param_groups, lr=float(lr))\n",
        "\n",
        "def objective(trial):\n",
        "    hp = suggest_hparams(trial)\n",
        "    layers = layers_from_arch(hp[\"arch\"])\n",
        "\n",
        "    # Build loaders with TRIAL-SPECIFIC batch size (smaller batches often regularize more)\n",
        "    bs = int(hp[\"batch_size\"])\n",
        "    tr_sampler = EventBalancedBatchSampler(ytr_event, bs, seed=42)\n",
        "    tr_loader = DataLoader(train_ds, batch_sampler=tr_sampler, num_workers=0)\n",
        "    tr_eval_loader = DataLoader(train_ds, batch_size=bs, shuffle=False, num_workers=0)\n",
        "    va_loader = DataLoader(valid_ds, batch_size=bs, shuffle=False, num_workers=0)\n",
        "\n",
        "    # Model / optimizer\n",
        "    model = DeepSurvMLP(in_dim, layers, dropout=hp[\"dropout\"]).to(device)\n",
        "    optimizer = make_optimizer_hpo(model, lr=hp[\"lr\"], wd=hp[\"wd\"],\n",
        "                                   apply_final_wd=bool(hp[\"apply_final_wd\"]))\n",
        "\n",
        "    # Scheduler per trial\n",
        "    epochs = int(min(hp[\"epochs\"], MAX_EPOCHS_CAP))\n",
        "    if hp[\"sched\"] == \"cosine\":\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "        def step_sched(epoch_idx): scheduler.step()\n",
        "    elif hp[\"sched\"] == \"cawr\":\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            optimizer, T_0=int(hp[\"cawr_T0\"]), T_mult=int(hp[\"cawr_Tmult\"])\n",
        "        )\n",
        "        def step_sched(epoch_idx): scheduler.step(epoch_idx + 1)\n",
        "    else:\n",
        "        scheduler = None\n",
        "        def step_sched(epoch_idx): pass\n",
        "\n",
        "    best_val_ci = -np.inf\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Warm-up schedules for dropout & WD\n",
        "        frac_d = min(1.0, epoch / float(WARMUP_EPOCHS_DROPOUT))\n",
        "        frac_w = min(1.0, epoch / float(WARMUP_EPOCHS_WD))\n",
        "        set_dropout_p(model, DROPOUT_START + (hp['dropout'] - DROPOUT_START) * frac_d)\n",
        "        set_weight_decay(optimizer, WD_START + (hp['wd'] - WD_START) * frac_w)\n",
        "\n",
        "        # One epoch + full risk-set step with extra regularizers\n",
        "        stats = train_one_epoch_reg(\n",
        "            model, optimizer, tr_loader, device,\n",
        "            l1_lambda=hp[\"l1\"], epoch=epoch, warmup_epochs=WARMUP_EPOCHS_L1,\n",
        "            input_dropout=hp[\"input_dropout\"], noise_std=hp[\"noise_std\"],\n",
        "            grad_clip=hp[\"grad_clip\"]\n",
        "        )\n",
        "        _ = full_risk_set_step_reg(\n",
        "            model, optimizer, train_ds, device,\n",
        "            l1_lambda=hp[\"l1\"], warm=stats['warm'],\n",
        "            input_dropout=hp[\"input_dropout\"], noise_std=hp[\"noise_std\"],\n",
        "            grad_clip=hp[\"grad_clip\"]\n",
        "        )\n",
        "\n",
        "        # Evaluate\n",
        "        val_ci = evaluate_ci(model, va_loader, device)\n",
        "        step_sched(epoch)\n",
        "\n",
        "        # Report for pruning\n",
        "        trial.report(val_ci, step=epoch)\n",
        "        if val_ci > best_val_ci:\n",
        "            best_val_ci = val_ci\n",
        "            best_epoch = epoch + 1\n",
        "\n",
        "        if trial.should_prune():\n",
        "            # Clean up GPU mem before pruning\n",
        "            del model, optimizer, scheduler\n",
        "            if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    trial.set_user_attr(\"best_epoch\", int(best_epoch))\n",
        "\n",
        "    # Clean up\n",
        "    del model, optimizer, scheduler\n",
        "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return best_val_ci\n",
        "\n",
        "# ---- Study / Sampler / Pruner (tune TPE a bit for broader exploration) ----\n",
        "storage = \"sqlite:///deepsurv_optuna.db\"\n",
        "study_name = \"deepsurv_cox_hpo_overfit_reducer\"\n",
        "\n",
        "sampler = optuna.samplers.TPESampler(\n",
        "    seed=42,\n",
        "    multivariate=True,\n",
        "    group=True,\n",
        "    n_startup_trials=40,       # explore more before exploitation\n",
        "    constant_liar=True,        # better parallel behavior if you run parallel\n",
        "    consider_prior=True\n",
        ")\n",
        "\n",
        "# Hyperband/SH both work; Hyperband gives a bit more flexibility across resource levels\n",
        "pruner = optuna.pruners.HyperbandPruner(min_resource=16, reduction_factor=3)\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",       # single objective (Val CI)\n",
        "    study_name=study_name,\n",
        "    storage=storage,\n",
        "    load_if_exists=True,\n",
        "    sampler=sampler,\n",
        "    pruner=pruner\n",
        ")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Launch Optuna Dashboard (Colab proxied URL printed)\n",
        "#   (No unsupported args; previous TypeError fixed)\n",
        "# ============================================================\n",
        "try:\n",
        "    from optuna_dashboard import run_server\n",
        "    from google.colab import output\n",
        "    import portpicker\n",
        "    PORT = portpicker.pick_unused_port()\n",
        "    def _start_dashboard():\n",
        "        # NOTE: do NOT pass unsupported kwargs like reload/quiet\n",
        "        run_server(storage, host=\"0.0.0.0\", port=PORT)\n",
        "    t = threading.Thread(target=_start_dashboard, daemon=True)\n",
        "    t.start()\n",
        "    time.sleep(2)\n",
        "    dash_url = output.eval_js(f\"google.colab.kernel.proxyPort({PORT}, {{'cache': false}})\")\n",
        "    print(\"Optuna Dashboard:\", dash_url)\n",
        "except Exception as ex:\n",
        "    print(\"[Optuna Dashboard] Could not start dashboard automatically.\", ex)\n",
        "    print(\"You can run it locally with:  optuna-dashboard sqlite:///deepsurv_optuna.db\")\n",
        "\n",
        "# ============================================================\n",
        "# Run Optimization\n",
        "# ============================================================\n",
        "N_TRIALS = 100  # adjust as needed\n",
        "print(f\"Starting optimization: {N_TRIALS} trials × up to {MAX_EPOCHS_CAP} epochs\")\n",
        "study.optimize(objective, n_trials=N_TRIALS, gc_after_trial=True)\n",
        "\n",
        "print(\"\\n[Best] Val CI:\", study.best_value)\n",
        "print(\"[Best] Params:\", study.best_params)\n",
        "print(\"[Best] Best epoch:\", study.best_trial.user_attrs.get(\"best_epoch\", MAX_EPOCHS_CAP))\n",
        "\n",
        "# ============================================================\n",
        "# Retrain on Train+Val with best hyperparams; evaluate Test\n",
        "# - Combine Train+Val, sort, restandardize; apply to Test\n",
        "# ============================================================\n",
        "# Prepare Train+Val\n",
        "trainval_df = pd.concat([train_df, valid_df], axis=0, ignore_index=True)\n",
        "trainval_df = trainval_df.sort_values(by=[\"OS_MONTHS\",\"OS_STATUS\"], ascending=[False, False]).reset_index(drop=True)\n",
        "\n",
        "X_trv = trainval_df[feat_candidates].values.astype(np.float32)\n",
        "y_trv_time = trainval_df[\"OS_MONTHS\"].values.astype(np.float32)\n",
        "y_trv_event = trainval_df[\"OS_STATUS\"].values.astype(int)\n",
        "\n",
        "# Median impute by Train+Val medians (for retraining phase)\n",
        "trv_medians = np.nanmedian(X_trv, axis=0)\n",
        "X_trv = np.where(np.isnan(X_trv), trv_medians, X_trv)\n",
        "\n",
        "scaler_trv = StandardScaler().fit(X_trv)\n",
        "X_trv = scaler_trv.transform(X_trv).astype(np.float32)\n",
        "\n",
        "# Test set standardized with Train+Val scaler\n",
        "X_test = test_df[feat_candidates].values.astype(np.float32)\n",
        "X_test = np.where(np.isnan(X_test), trv_medians, X_test)\n",
        "X_test = scaler_trv.transform(X_test).astype(np.float32)\n",
        "y_te_time = test_df[\"OS_MONTHS\"].values.astype(np.float32)\n",
        "y_te_event = test_df[\"OS_STATUS\"].values.astype(int)\n",
        "\n",
        "# Loaders\n",
        "BATCH_SIZE = 64\n",
        "trv_ds = SurvivalDataset(X_trv, y_trv_time, y_trv_event)\n",
        "te_ds  = SurvivalDataset(X_test, y_te_time, y_te_event)\n",
        "\n",
        "trv_sampler = EventBalancedBatchSampler(y_trv_event, BATCH_SIZE, seed=7)\n",
        "trv_loader  = DataLoader(trv_ds, batch_sampler=trv_sampler, num_workers=0)\n",
        "trv_eval_loader = DataLoader(trv_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "te_loader  = DataLoader(te_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "# Build & train final model\n",
        "best_hp = study.best_params\n",
        "l1_final = float(best_hp.get(\"l1\", 0.0))\n",
        "best_layers = layers_from_arch(best_hp[\"arch\"])\n",
        "best_n_epochs = int(study.best_trial.user_attrs.get(\"best_epoch\", MAX_EPOCHS_CAP))\n",
        "best_n_epochs = max(16, min(best_n_epochs, MAX_EPOCHS_CAP))\n",
        "\n",
        "model_final = DeepSurvMLP(in_dim, best_layers, dropout=best_hp[\"dropout\"]).to(device)\n",
        "opt_final = make_optimizer(model_final, lr=best_hp[\"lr\"], wd=best_hp[\"wd\"])\n",
        "sched_final = torch.optim.lr_scheduler.CosineAnnealingLR(opt_final, T_max=best_n_epochs)\n",
        "\n",
        "for epoch in range(best_n_epochs):\n",
        "    frac_d = min(1.0, epoch / float(WARMUP_EPOCHS_DROPOUT))\n",
        "    frac_w = min(1.0, epoch / float(WARMUP_EPOCHS_WD))\n",
        "    set_dropout_p(model_final, DROPOUT_START + (best_hp['dropout'] - DROPOUT_START) * frac_d)\n",
        "    set_weight_decay(opt_final, WD_START + (best_hp['wd'] - WD_START) * frac_w)\n",
        "\n",
        "    stats = train_one_epoch(model_final, opt_final, trv_loader, device, l1_lambda=best_hp[\"l1\"],\n",
        "                            epoch=epoch, warmup_epochs=WARMUP_EPOCHS_L1)\n",
        "    _ = full_risk_set_step(model_final, opt_final, trv_ds, device, l1_lambda=best_hp[\"l1\"], warm=stats['warm'])\n",
        "    sched_final.step()\n",
        "\n",
        "# Evaluate\n",
        "trainval_ci = evaluate_ci(model_final, trv_eval_loader, device)\n",
        "test_ci = evaluate_ci(model_final, te_loader, device)\n",
        "print(f\"\\n[Final] Train+Val CI: {trainval_ci:.4f}\")\n",
        "print(f\"[Final] Test CI:      {test_ci:.4f}\")\n",
        "\n",
        "# (Optional) Save artifacts to Drive\n",
        "OUT_DIR = \"/content/drive/MyDrive/deepsurv_results_optuna\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "torch.save(model_final.state_dict(), os.path.join(OUT_DIR, \"deepsurv_best.pt\"))\n",
        "with open(os.path.join(OUT_DIR, \"best_params.txt\"), \"w\") as f:\n",
        "    f.write(str(study.best_params))\n",
        "print(\"Saved final model and best params to:\", OUT_DIR)\n"
      ],
      "metadata": {
        "id": "lbcrdoE4tyWq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62a7114b-6b41-4c16-b468-a3ea1a9f8ad5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Device: cuda\n",
            "Genes.csv path: /content/drive/MyDrive/Genes.csv\n",
            "[Genes] Selected 1555 genes with Prop == 1\n",
            "[Features] Using 1573 common features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2650183406.py:263: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"Adjuvant Chemo\"] = df[\"Adjuvant Chemo\"].replace({\"OBS\":0, \"ACT\":1})\n",
            "/tmp/ipython-input-2650183406.py:263: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"Adjuvant Chemo\"] = df[\"Adjuvant Chemo\"].replace({\"OBS\":0, \"ACT\":1})\n",
            "/tmp/ipython-input-2650183406.py:263: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"Adjuvant Chemo\"] = df[\"Adjuvant Chemo\"].replace({\"OBS\":0, \"ACT\":1})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input dim: 1573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``group`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "[I 2025-10-19 05:02:14,045] A new study created in RDB with name: deepsurv_cox_hpo_overfit_reducer\n",
            "Bottle v0.13.4 server starting up (using WSGIRefServer())...\n",
            "Listening on http://0.0.0.0:40971/\n",
            "Hit Ctrl-C to quit.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optuna Dashboard: https://40971-gpu-t4-s-104ldvpjndb22-c.asia-southeast1-1.prod.colab.dev\n",
            "Starting optimization: 100 trials × up to 512 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [19/Oct/2025 05:02:24] \"GET / HTTP/1.1\" 302 0\n",
            "127.0.0.1 - - [19/Oct/2025 05:02:30] \"GET / HTTP/1.1\" 302 0\n",
            "127.0.0.1 - - [19/Oct/2025 05:02:35] \"GET / HTTP/1.1\" 302 0\n",
            "127.0.0.1 - - [19/Oct/2025 05:03:57] \"GET / HTTP/1.1\" 302 0\n",
            "[I 2025-10-19 05:04:51,571] Trial 0 finished with value: 0.6583796000589593 and parameters: {'arch': '128-128', 'dropout': 0.27473748411882515, 'input_dropout': 0.18355586841671384, 'wd': 4.982752357076453e-06, 'apply_final_wd': 1, 'use_l1': 1, 'l1': 1.240616395320886e-07, 'lr': 7.475992999956501e-05, 'sched': 'none', 'epochs': 128, 'batch_size': 128, 'grad_clip': 8.275576133048151, 'noise_std': 0.03046137691733707}. Best is trial 0 with value: 0.6583796000589593.\n",
            "[I 2025-10-19 05:06:08,099] Trial 1 finished with value: 0.6681570284478947 and parameters: {'arch': '256-256', 'dropout': 0.1530955012311517, 'input_dropout': 0.058794858725743554, 'wd': 1.6832027985721922e-06, 'apply_final_wd': 1, 'use_l1': 1, 'l1': 8.994587030462112e-07, 'lr': 3.001230180898045e-05, 'sched': 'none', 'epochs': 96, 'batch_size': 32, 'grad_clip': 1.0496990541124216, 'noise_std': 0.08154614284548342}. Best is trial 1 with value: 0.6681570284478947.\n",
            "[I 2025-10-19 05:06:56,148] Trial 2 pruned. \n",
            "[I 2025-10-19 05:07:10,048] Trial 3 pruned. \n",
            "[I 2025-10-19 05:13:38,663] Trial 4 finished with value: 0.6762639414336953 and parameters: {'arch': '32-16', 'dropout': 0.21191110623991255, 'input_dropout': 0.012232542466429174, 'wd': 0.0009004606022643075, 'apply_final_wd': 0, 'use_l1': 0, 'lr': 0.0001247754711757969, 'sched': 'cawr', 'cawr_T0': 80, 'cawr_Tmult': 2, 'epochs': 480, 'batch_size': 32, 'grad_clip': 8.354999801810942, 'noise_std': 0.055520081159946236}. Best is trial 4 with value: 0.6762639414336953.\n",
            "[I 2025-10-19 05:14:17,578] Trial 5 pruned. \n",
            "[I 2025-10-19 05:15:11,170] Trial 6 pruned. \n",
            "[I 2025-10-19 05:15:24,624] Trial 7 pruned. \n",
            "[I 2025-10-19 05:15:42,191] Trial 8 pruned. \n",
            "[I 2025-10-19 05:15:56,031] Trial 9 pruned. \n",
            "[I 2025-10-19 05:16:10,160] Trial 10 pruned. \n",
            "[I 2025-10-19 05:16:29,523] Trial 11 pruned. \n",
            "[I 2025-10-19 05:16:47,227] Trial 12 pruned. \n",
            "[I 2025-10-19 05:17:04,072] Trial 13 pruned. \n",
            "[I 2025-10-19 05:17:23,748] Trial 14 pruned. \n",
            "[I 2025-10-19 05:17:37,756] Trial 15 pruned. \n",
            "[I 2025-10-19 05:18:16,894] Trial 16 pruned. \n",
            "[I 2025-10-19 05:18:36,598] Trial 17 pruned. \n",
            "[I 2025-10-19 05:19:24,480] Trial 18 pruned. \n",
            "[I 2025-10-19 05:20:19,508] Trial 19 pruned. \n",
            "[I 2025-10-19 05:20:58,450] Trial 20 pruned. \n",
            "[I 2025-10-19 05:21:17,935] Trial 21 pruned. \n",
            "[I 2025-10-19 05:22:14,453] Trial 22 pruned. \n",
            "[I 2025-10-19 05:22:33,799] Trial 23 pruned. \n",
            "[I 2025-10-19 05:22:47,656] Trial 24 pruned. \n",
            "[I 2025-10-19 05:23:35,794] Trial 25 pruned. \n",
            "[I 2025-10-19 05:25:42,842] Trial 26 finished with value: 0.6832899326880558 and parameters: {'arch': '256-128-64', 'dropout': 0.3676034637747735, 'input_dropout': 0.05553987865158589, 'wd': 0.0005122768576871507, 'apply_final_wd': 0, 'use_l1': 0, 'lr': 0.00015002274853637062, 'sched': 'cosine', 'epochs': 160, 'batch_size': 32, 'grad_clip': 7.350176552641196, 'noise_std': 0.09252483174156659}. Best is trial 26 with value: 0.6832899326880558.\n",
            "[I 2025-10-19 05:26:02,073] Trial 27 pruned. \n",
            "[I 2025-10-19 05:26:40,869] Trial 28 pruned. \n",
            "[I 2025-10-19 05:26:54,628] Trial 29 pruned. \n",
            "[I 2025-10-19 05:27:41,187] Trial 30 pruned. \n",
            "[I 2025-10-19 05:30:22,804] Trial 31 pruned. \n",
            "[I 2025-10-19 05:31:10,789] Trial 32 pruned. \n",
            "[I 2025-10-19 05:36:53,638] Trial 33 pruned. \n",
            "[I 2025-10-19 05:37:41,618] Trial 34 pruned. \n",
            "[I 2025-10-19 05:37:58,469] Trial 35 pruned. \n",
            "[I 2025-10-19 05:38:17,827] Trial 36 pruned. \n",
            "[I 2025-10-19 05:38:35,387] Trial 37 pruned. \n",
            "[I 2025-10-19 05:39:14,281] Trial 38 pruned. \n",
            "[I 2025-10-19 05:39:33,468] Trial 39 pruned. \n",
            "[I 2025-10-19 05:40:12,670] Trial 40 pruned. \n",
            "[I 2025-10-19 05:40:51,709] Trial 41 pruned. \n",
            "[I 2025-10-19 05:41:39,249] Trial 42 pruned. \n",
            "[I 2025-10-19 05:42:17,895] Trial 43 pruned. \n",
            "[I 2025-10-19 05:42:31,524] Trial 44 pruned. \n",
            "[I 2025-10-19 05:42:50,748] Trial 45 pruned. \n",
            "[I 2025-10-19 05:43:04,393] Trial 46 pruned. \n",
            "[I 2025-10-19 05:44:16,712] Trial 47 finished with value: 0.6597061858202722 and parameters: {'arch': '128', 'dropout': 0.11442755801786375, 'input_dropout': 0.06832718910495672, 'wd': 2.0049789914433672e-05, 'apply_final_wd': 1, 'use_l1': 1, 'l1': 2.257741337394224e-07, 'lr': 2.063322863696053e-05, 'sched': 'none', 'epochs': 64, 'batch_size': 128, 'grad_clip': 1.174739894540859, 'noise_std': 0.0980458996502955}. Best is trial 26 with value: 0.6832899326880558.\n",
            "[I 2025-10-19 05:45:11,394] Trial 48 pruned. \n",
            "[I 2025-10-19 05:45:25,045] Trial 49 pruned. \n",
            "[I 2025-10-19 05:46:03,335] Trial 50 pruned. \n",
            "[I 2025-10-19 05:46:42,439] Trial 51 pruned. \n",
            "[I 2025-10-19 05:49:03,734] Trial 52 pruned. \n",
            "[I 2025-10-19 05:49:23,295] Trial 53 pruned. \n",
            "[I 2025-10-19 05:49:43,526] Trial 54 pruned. \n",
            "[I 2025-10-19 05:50:38,617] Trial 55 pruned. \n",
            "[I 2025-10-19 05:50:52,661] Trial 56 pruned. \n",
            "[I 2025-10-19 05:51:43,230] Trial 57 finished with value: 0.674003832358866 and parameters: {'arch': '128-128', 'dropout': 0.3454721575106764, 'input_dropout': 0.13437444678081195, 'wd': 2.568182127079851e-05, 'apply_final_wd': 0, 'use_l1': 0, 'lr': 0.00016541299574282368, 'sched': 'cosine', 'epochs': 64, 'batch_size': 32, 'grad_clip': 7.754495440500207, 'noise_std': 0.09654816619940412}. Best is trial 26 with value: 0.6832899326880558.\n",
            "[I 2025-10-19 05:52:22,244] Trial 58 pruned. \n",
            "[I 2025-10-19 05:52:36,222] Trial 59 pruned. \n",
            "[I 2025-10-19 05:53:26,350] Trial 60 finished with value: 0.6796541050459391 and parameters: {'arch': '512', 'dropout': 0.36466067137191127, 'input_dropout': 0.0927457346640437, 'wd': 3.7144676624644133e-06, 'apply_final_wd': 0, 'use_l1': 0, 'lr': 0.00018119974782711092, 'sched': 'cosine', 'epochs': 64, 'batch_size': 32, 'grad_clip': 8.425904791843166, 'noise_std': 0.08964836863088955}. Best is trial 26 with value: 0.6832899326880558.\n",
            "[I 2025-10-19 05:55:06,042] Trial 61 finished with value: 0.6861887682405542 and parameters: {'arch': '512', 'dropout': 0.417767479593417, 'input_dropout': 0.0759753632120309, 'wd': 4.515313326287201e-06, 'apply_final_wd': 0, 'use_l1': 0, 'lr': 0.00010018397076346876, 'sched': 'cosine', 'epochs': 128, 'batch_size': 32, 'grad_clip': 9.205723250463013, 'noise_std': 0.08942019457563379}. Best is trial 61 with value: 0.6861887682405542.\n",
            "[I 2025-10-19 05:56:45,877] Trial 62 finished with value: 0.6783275192846263 and parameters: {'arch': '128-128', 'dropout': 0.3519338907792114, 'input_dropout': 0.18327201970862603, 'wd': 1.9605039357497316e-05, 'apply_final_wd': 0, 'use_l1': 0, 'lr': 0.0001210605798800891, 'sched': 'cosine', 'epochs': 128, 'batch_size': 32, 'grad_clip': 8.40663761128776, 'noise_std': 0.0946917277270488}. Best is trial 61 with value: 0.6861887682405542.\n",
            "[I 2025-10-19 05:59:13,463] Trial 63 finished with value: 0.6930673610769911 and parameters: {'arch': '512', 'dropout': 0.385912835673872, 'input_dropout': 0.061771953713056, 'wd': 3.3415205446076416e-06, 'apply_final_wd': 0, 'use_l1': 0, 'lr': 6.945321990789577e-05, 'sched': 'cosine', 'epochs': 192, 'batch_size': 32, 'grad_clip': 8.251469896233349, 'noise_std': 0.09246940755563608}. Best is trial 63 with value: 0.6930673610769911.\n",
            "[I 2025-10-19 05:59:50,481] Trial 64 pruned. \n",
            "[I 2025-10-19 06:00:45,993] Trial 65 pruned. \n",
            "[I 2025-10-19 06:02:39,872] Trial 66 pruned. \n",
            "[I 2025-10-19 06:04:32,624] Trial 67 pruned. \n",
            "[I 2025-10-19 06:05:22,963] Trial 68 finished with value: 0.676951800717339 and parameters: {'arch': '16', 'dropout': 0.4650381555999209, 'input_dropout': 0.20733778297094876, 'wd': 9.044541549905823e-05, 'apply_final_wd': 0, 'use_l1': 0, 'lr': 0.00020532965062932721, 'sched': 'cosine', 'epochs': 64, 'batch_size': 32, 'grad_clip': 7.833599591486148, 'noise_std': 0.08979769934357425}. Best is trial 63 with value: 0.6930673610769911.\n",
            "[I 2025-10-19 06:06:01,452] Trial 69 pruned. \n",
            "[I 2025-10-19 06:06:40,306] Trial 70 pruned. \n",
            "[I 2025-10-19 06:07:18,579] Trial 71 pruned. \n",
            "[I 2025-10-19 06:08:56,957] Trial 72 finished with value: 0.6806858939714047 and parameters: {'arch': '64', 'dropout': 0.2657993650125349, 'input_dropout': 0.1670976739771317, 'wd': 1.1848522692314531e-05, 'apply_final_wd': 0, 'use_l1': 0, 'lr': 0.00014936600252416215, 'sched': 'cawr', 'cawr_T0': 80, 'cawr_Tmult': 1, 'epochs': 128, 'batch_size': 32, 'grad_clip': 4.89704758920994, 'noise_std': 0.09706820777310418}. Best is trial 63 with value: 0.6930673610769911.\n",
            "[I 2025-10-19 06:09:16,849] Trial 73 pruned. \n",
            "[I 2025-10-19 06:11:10,003] Trial 74 pruned. \n",
            "[I 2025-10-19 06:11:27,114] Trial 75 pruned. \n",
            "[I 2025-10-19 06:13:05,604] Trial 76 finished with value: 0.6718911217019604 and parameters: {'arch': '64', 'dropout': 0.11513613365211481, 'input_dropout': 0.14537423290578574, 'wd': 1.9472846962420083e-06, 'apply_final_wd': 0, 'use_l1': 0, 'lr': 0.00017292146364987775, 'sched': 'cawr', 'cawr_T0': 80, 'cawr_Tmult': 2, 'epochs': 128, 'batch_size': 32, 'grad_clip': 3.203966342262196, 'noise_std': 0.09753306442073732}. Best is trial 63 with value: 0.6930673610769911.\n",
            "[I 2025-10-19 06:14:20,390] Trial 77 finished with value: 0.683388198300005 and parameters: {'arch': '32-16', 'dropout': 0.5201675751498304, 'input_dropout': 0.1972301247999172, 'wd': 2.0620188898819965e-06, 'apply_final_wd': 0, 'use_l1': 0, 'lr': 0.0003588187705855253, 'sched': 'none', 'epochs': 96, 'batch_size': 32, 'grad_clip': 6.662696620159573, 'noise_std': 0.08030597507274755}. Best is trial 63 with value: 0.6930673610769911.\n",
            "[I 2025-10-19 06:14:58,849] Trial 78 pruned. \n",
            "[I 2025-10-19 06:15:15,382] Trial 79 pruned. \n",
            "[I 2025-10-19 06:15:34,796] Trial 80 pruned. \n",
            "[I 2025-10-19 06:15:48,349] Trial 81 pruned. \n",
            "[I 2025-10-19 06:16:37,738] Trial 82 finished with value: 0.6747408244484843 and parameters: {'arch': '512', 'dropout': 0.44248713440025256, 'input_dropout': 0.2512065957501063, 'wd': 1.6966890659303932e-05, 'apply_final_wd': 0, 'use_l1': 1, 'l1': 0.0026413845559635774, 'lr': 0.0003064094784018035, 'sched': 'cosine', 'epochs': 64, 'batch_size': 32, 'grad_clip': 8.690928068896916, 'noise_std': 0.07237487749926498}. Best is trial 63 with value: 0.6930673610769911.\n",
            "[I 2025-10-19 06:16:51,399] Trial 83 pruned. \n",
            "[I 2025-10-19 06:18:43,864] Trial 84 pruned. \n",
            "[I 2025-10-19 06:21:46,330] Trial 85 finished with value: 0.6837812607478013 and parameters: {'arch': '256-128-64', 'dropout': 0.2671715059195588, 'input_dropout': 0.07691134905251565, 'wd': 0.0005859474131017057, 'apply_final_wd': 0, 'use_l1': 0, 'lr': 0.0002684341886979816, 'sched': 'none', 'epochs': 192, 'batch_size': 64, 'grad_clip': 6.207186498959876, 'noise_std': 0.08390536645079039}. Best is trial 63 with value: 0.6930673610769911.\n",
            "[I 2025-10-19 06:22:02,697] Trial 86 pruned. \n",
            "[I 2025-10-19 06:22:16,437] Trial 87 pruned. \n",
            "[I 2025-10-19 06:22:33,427] Trial 88 pruned. \n",
            "[I 2025-10-19 06:23:11,063] Trial 89 pruned. \n",
            "[I 2025-10-19 06:23:28,345] Trial 90 pruned. \n",
            "[I 2025-10-19 06:24:18,612] Trial 91 finished with value: 0.6801454331056846 and parameters: {'arch': '256-128-64', 'dropout': 0.3626203903689041, 'input_dropout': 0.088502517406936, 'wd': 0.0007032418285928833, 'apply_final_wd': 0, 'use_l1': 0, 'lr': 0.0004890184744181396, 'sched': 'cosine', 'epochs': 64, 'batch_size': 32, 'grad_clip': 5.456386597979759, 'noise_std': 0.09378106234401024}. Best is trial 63 with value: 0.6930673610769911.\n",
            "[I 2025-10-19 06:24:56,573] Trial 92 pruned. \n",
            "[I 2025-10-19 06:26:49,388] Trial 93 pruned. \n",
            "[I 2025-10-19 06:27:28,256] Trial 94 pruned. \n",
            "[I 2025-10-19 06:28:06,579] Trial 95 pruned. \n",
            "[I 2025-10-19 06:28:56,157] Trial 96 finished with value: 0.6894315334348745 and parameters: {'arch': '256', 'dropout': 0.4056569627448831, 'input_dropout': 0.20917129020339692, 'wd': 0.001985123028782202, 'apply_final_wd': 1, 'use_l1': 0, 'lr': 0.00021767935345693497, 'sched': 'cosine', 'epochs': 64, 'batch_size': 32, 'grad_clip': 9.581765350185416, 'noise_std': 0.08779979918745631}. Best is trial 63 with value: 0.6930673610769911.\n",
            "[I 2025-10-19 06:30:08,588] Trial 97 finished with value: 0.6732668402692478 and parameters: {'arch': '128', 'dropout': 0.3038006358220286, 'input_dropout': 0.20900476777078672, 'wd': 0.0010461593351890248, 'apply_final_wd': 1, 'use_l1': 0, 'lr': 8.953945641953046e-05, 'sched': 'cosine', 'epochs': 96, 'batch_size': 32, 'grad_clip': 9.441709147629439, 'noise_std': 0.0719180310987583}. Best is trial 63 with value: 0.6930673610769911.\n",
            "[I 2025-10-19 06:30:25,758] Trial 98 pruned. \n",
            "[I 2025-10-19 06:30:39,119] Trial 99 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Best] Val CI: 0.6930673610769911\n",
            "[Best] Params: {'arch': '512', 'dropout': 0.385912835673872, 'input_dropout': 0.061771953713056, 'wd': 3.3415205446076416e-06, 'apply_final_wd': 0, 'use_l1': 0, 'lr': 6.945321990789577e-05, 'sched': 'cosine', 'epochs': 192, 'batch_size': 32, 'grad_clip': 8.251469896233349, 'noise_std': 0.09246940755563608}\n",
            "[Best] Best epoch: 26\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'l1'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2650183406.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0mset_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWD_START\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbest_hp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wd'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mWD_START\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfrac_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m     stats = train_one_epoch(model_final, opt_final, trv_loader, device, l1_lambda=best_hp[\"l1\"],\n\u001b[0m\u001b[1;32m    682\u001b[0m                             epoch=epoch, warmup_epochs=WARMUP_EPOCHS_L1)\n\u001b[1;32m    683\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_risk_set_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrv_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_hp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"l1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'warm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'l1'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Ready-to-run: Retrain on Train+Val with given best params, then eval on Test ====\n",
        "\n",
        "# --- Use the reported best params & epoch (handles missing 'l1') ---\n",
        "best_hp = {\n",
        "    'arch': '512',\n",
        "    'dropout': 0.385912835673872,\n",
        "    'input_dropout': 0.061771953713056,  # not used in final fit below\n",
        "    'wd': 3.3415205446076416e-06,\n",
        "    'apply_final_wd': 0,                 # not used in final fit below\n",
        "    'use_l1': 0,\n",
        "    'lr': 6.945321990789577e-05,\n",
        "    'sched': 'cosine',\n",
        "    'epochs': 192,\n",
        "    'batch_size': 32,\n",
        "    'grad_clip': 8.251469896233349,      # not used in final fit below\n",
        "    'noise_std': 0.09246940755563608     # not used in final fit below\n",
        "}\n",
        "best_n_epochs = 26\n",
        "l1_final = float(best_hp.get(\"l1\", 0.0))  # <- fix: default L1 when use_l1==0\n",
        "\n",
        "# --- Build Train+Val, restandardize; transform Test ---\n",
        "trainval_df = pd.concat([train_df, valid_df], axis=0, ignore_index=True)\n",
        "trainval_df = trainval_df.sort_values(by=[\"OS_MONTHS\",\"OS_STATUS\"], ascending=[False, False]).reset_index(drop=True)\n",
        "\n",
        "X_trv = trainval_df[feat_candidates].values.astype(np.float32)\n",
        "y_trv_time = trainval_df[\"OS_MONTHS\"].values.astype(np.float32)\n",
        "y_trv_event = trainval_df[\"OS_STATUS\"].values.astype(int)\n",
        "\n",
        "trv_medians = np.nanmedian(X_trv, axis=0)\n",
        "X_trv = np.where(np.isnan(X_trv), trv_medians, X_trv)\n",
        "scaler_trv = StandardScaler().fit(X_trv)\n",
        "X_trv = scaler_trv.transform(X_trv).astype(np.float32)\n",
        "\n",
        "X_test = test_df[feat_candidates].values.astype(np.float32)\n",
        "X_test = np.where(np.isnan(X_test), trv_medians, X_test)\n",
        "X_test = scaler_trv.transform(X_test).astype(np.float32)\n",
        "y_te_time = test_df[\"OS_MONTHS\"].values.astype(np.float32)\n",
        "y_te_event = test_df[\"OS_STATUS\"].values.astype(int)\n",
        "\n",
        "# --- Datasets & Loaders ---\n",
        "BATCH_SIZE = 64\n",
        "trv_ds = SurvivalDataset(X_trv, y_trv_time, y_trv_event)\n",
        "te_ds  = SurvivalDataset(X_test, y_te_time, y_te_event)\n",
        "\n",
        "trv_sampler = EventBalancedBatchSampler(y_trv_event, BATCH_SIZE, seed=7)\n",
        "trv_loader  = DataLoader(trv_ds, batch_sampler=trv_sampler, num_workers=0)\n",
        "trv_eval_loader = DataLoader(trv_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "te_loader  = DataLoader(te_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "# --- Model (arch parsed from string), Optim, Scheduler ---\n",
        "def layers_from_arch(arch_str: str):\n",
        "    return [int(x) for x in arch_str.split(\"-\") if x.strip()]\n",
        "\n",
        "in_dim = X_trv.shape[1]\n",
        "best_layers = layers_from_arch(best_hp[\"arch\"])\n",
        "\n",
        "model_final = DeepSurvMLP(in_dim, best_layers, dropout=best_hp[\"dropout\"]).to(device)\n",
        "opt_final = make_optimizer(model_final, lr=best_hp[\"lr\"], wd=best_hp[\"wd\"])\n",
        "sched_final = torch.optim.lr_scheduler.CosineAnnealingLR(opt_final, T_max=best_n_epochs)\n",
        "\n",
        "# --- Warmups (reuse constants from earlier cell if present; else define sane defaults) ---\n",
        "try:\n",
        "    WARMUP_EPOCHS_DROPOUT\n",
        "except NameError:\n",
        "    WARMUP_EPOCHS_DROPOUT = 30\n",
        "    WARMUP_EPOCHS_WD = 30\n",
        "    WARMUP_EPOCHS_L1 = 30\n",
        "    DROPOUT_START = 0.15\n",
        "    WD_START = 0.0\n",
        "\n",
        "# --- Train ---\n",
        "for epoch in range(best_n_epochs):\n",
        "    frac_d = min(1.0, epoch / float(WARMUP_EPOCHS_DROPOUT))\n",
        "    frac_w = min(1.0, epoch / float(WARMUP_EPOCHS_WD))\n",
        "    set_dropout_p(model_final, DROPOUT_START + (best_hp['dropout'] - DROPOUT_START) * frac_d)\n",
        "    set_weight_decay(opt_final, WD_START + (best_hp['wd'] - WD_START) * frac_w)\n",
        "\n",
        "    stats = train_one_epoch(model_final, opt_final, trv_loader, device, l1_lambda=l1_final,\n",
        "                            epoch=epoch, warmup_epochs=WARMUP_EPOCHS_L1)\n",
        "    _ = full_risk_set_step(model_final, opt_final, trv_ds, device, l1_lambda=l1_final, warm=stats['warm'])\n",
        "    sched_final.step()\n",
        "\n",
        "# --- Evaluate ---\n",
        "trainval_ci = evaluate_ci(model_final, trv_eval_loader, device)\n",
        "test_ci = evaluate_ci(model_final, te_loader, device)\n",
        "print(f\"\\n[Final] Train+Val CI: {trainval_ci:.4f}\")\n",
        "print(f\"[Final] Test CI:      {test_ci:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4PSFDyjMEea",
        "outputId": "5724b04b-5c1f-4a90-bb0e-7d50609a1142"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Final] Train+Val CI: 0.7981\n",
            "[Final] Test CI:      0.6103\n"
          ]
        }
      ]
    }
  ]
}