{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1EY87_PKv0dTOF6mK_Kx8YPzRYVzJ6o-8",
      "authorship_tag": "ABX9TyN2Cwwqrps8lj/5N74QnLZR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osun24/nsclc-adj-chemo/blob/main/TorchSurv_DeepSurv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install torchsurv scikit-survival\n",
        "\n",
        "# Import required packages\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "\n",
        "# (Optional) Mount Google Drive if you plan to load/save files there\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81TEvMle6mqs",
        "outputId": "164de9da-1068-429c-bdda-6a7d22c4bd96"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsurv in /usr/local/lib/python3.11/dist-packages (0.1.4)\n",
            "Requirement already satisfied: scikit-survival in /usr/local/lib/python3.11/dist-packages (0.24.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchsurv) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torchsurv) (1.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchsurv) (2.0.2)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (from torchsurv) (1.7.1)\n",
            "Requirement already satisfied: ecos in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (2.0.14)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (1.4.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (2.10.2)\n",
            "Requirement already satisfied: osqp<1.0.0,>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (0.6.7.post3)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<1.7,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (1.6.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.11/dist-packages (from osqp<1.0.0,>=0.6.3->scikit-survival) (0.1.7.post5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->scikit-survival) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->scikit-survival) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->scikit-survival) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.7,>=1.6.1->scikit-survival) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchsurv) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchsurv) (1.3.0)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics->torchsurv) (24.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics->torchsurv) (0.14.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics->torchsurv) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->scikit-survival) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchsurv) (3.0.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baO87aHV3DUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16fcd4c7-6b24-4d52-d5c2-2ef681b8405a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with layers=[32], dropout=0.0, lr=0.001, weight_decay=0.0\n",
            "Epoch 10/100 - Train Loss: 1.7421, Val CI: 0.5903\n",
            "Epoch 20/100 - Train Loss: 1.5670, Val CI: 0.6334\n",
            "Epoch 30/100 - Train Loss: 1.3232, Val CI: 0.6487\n",
            "Epoch 40/100 - Train Loss: 1.2721, Val CI: 0.6191\n",
            "Epoch 50/100 - Train Loss: 0.8419, Val CI: 0.6053\n",
            "Epoch 60/100 - Train Loss: 1.2674, Val CI: 0.6336\n",
            "Epoch 70/100 - Train Loss: 1.0104, Val CI: 0.6281\n",
            "Epoch 80/100 - Train Loss: 0.9398, Val CI: 0.6167\n",
            "Epoch 90/100 - Train Loss: 0.8571, Val CI: 0.6297\n",
            "Epoch 100/100 - Train Loss: 0.8985, Val CI: 0.6580\n",
            "Finished config: Val CI = 0.6624\n",
            "\n",
            "Training with layers=[32], dropout=0.0, lr=0.001, weight_decay=0.0001\n",
            "Epoch 10/100 - Train Loss: 2.2950, Val CI: 0.6258\n",
            "Epoch 20/100 - Train Loss: 1.1915, Val CI: 0.6359\n",
            "Epoch 30/100 - Train Loss: 1.0929, Val CI: 0.6160\n",
            "Epoch 40/100 - Train Loss: 1.1576, Val CI: 0.6489\n",
            "Epoch 50/100 - Train Loss: 0.9188, Val CI: 0.6573\n",
            "Epoch 60/100 - Train Loss: 0.7924, Val CI: 0.6182\n",
            "Epoch 70/100 - Train Loss: 0.7776, Val CI: 0.6191\n",
            "Epoch 80/100 - Train Loss: 0.8509, Val CI: 0.6293\n",
            "Epoch 90/100 - Train Loss: 1.0772, Val CI: 0.6476\n",
            "Epoch 100/100 - Train Loss: 0.7694, Val CI: 0.6324\n",
            "Finished config: Val CI = 0.6594\n",
            "\n",
            "Training with layers=[32], dropout=0.0, lr=0.001, weight_decay=0.001\n",
            "Epoch 10/100 - Train Loss: 1.7673, Val CI: 0.6206\n",
            "Epoch 20/100 - Train Loss: 1.3263, Val CI: 0.6566\n",
            "Epoch 30/100 - Train Loss: 1.1589, Val CI: 0.6514\n",
            "Epoch 40/100 - Train Loss: 1.3761, Val CI: 0.6122\n",
            "Epoch 50/100 - Train Loss: 1.1215, Val CI: 0.6081\n",
            "Epoch 60/100 - Train Loss: 0.8966, Val CI: 0.6641\n",
            "Epoch 70/100 - Train Loss: 0.8283, Val CI: 0.6640\n",
            "Epoch 80/100 - Train Loss: 0.9239, Val CI: 0.6562\n",
            "Epoch 90/100 - Train Loss: 0.8175, Val CI: 0.6486\n",
            "Epoch 100/100 - Train Loss: 0.7051, Val CI: 0.6429\n",
            "Finished config: Val CI = 0.6715\n",
            "\n",
            "Training with layers=[32], dropout=0.0, lr=0.01, weight_decay=0.0\n",
            "Epoch 10/100 - Train Loss: 2.2095, Val CI: 0.6560\n",
            "Epoch 20/100 - Train Loss: 2.1573, Val CI: 0.6736\n",
            "Epoch 30/100 - Train Loss: 1.4432, Val CI: 0.6341\n",
            "Epoch 40/100 - Train Loss: 1.4059, Val CI: 0.6180\n",
            "Epoch 50/100 - Train Loss: 1.4466, Val CI: 0.6497\n",
            "Epoch 60/100 - Train Loss: 1.4477, Val CI: 0.6520\n",
            "Epoch 70/100 - Train Loss: 1.3171, Val CI: 0.6496\n",
            "Epoch 80/100 - Train Loss: 0.9617, Val CI: 0.6778\n",
            "Epoch 90/100 - Train Loss: 1.4276, Val CI: 0.6756\n",
            "Epoch 100/100 - Train Loss: 1.3181, Val CI: 0.6583\n",
            "Finished config: Val CI = 0.6907\n",
            "\n",
            "Training with layers=[32], dropout=0.0, lr=0.01, weight_decay=0.0001\n",
            "Epoch 10/100 - Train Loss: 2.5404, Val CI: 0.6323\n",
            "Epoch 20/100 - Train Loss: 1.8089, Val CI: 0.6270\n",
            "Epoch 30/100 - Train Loss: 1.3278, Val CI: 0.6303\n",
            "Epoch 40/100 - Train Loss: 1.1736, Val CI: 0.6520\n",
            "Epoch 50/100 - Train Loss: 1.1103, Val CI: 0.6228\n",
            "Epoch 60/100 - Train Loss: 1.1491, Val CI: 0.6589\n",
            "Epoch 70/100 - Train Loss: 1.0702, Val CI: 0.6734\n",
            "Epoch 80/100 - Train Loss: 1.1448, Val CI: 0.6489\n",
            "Epoch 90/100 - Train Loss: 1.0198, Val CI: 0.6700\n",
            "Epoch 100/100 - Train Loss: 0.8325, Val CI: 0.6664\n",
            "Finished config: Val CI = 0.6941\n",
            "\n",
            "Training with layers=[32], dropout=0.0, lr=0.01, weight_decay=0.001\n",
            "Epoch 10/100 - Train Loss: 2.2355, Val CI: 0.6350\n",
            "Epoch 20/100 - Train Loss: 1.7815, Val CI: 0.6521\n",
            "Epoch 30/100 - Train Loss: 1.3564, Val CI: 0.6678\n",
            "Epoch 40/100 - Train Loss: 1.2589, Val CI: 0.6813\n",
            "Epoch 50/100 - Train Loss: 1.1738, Val CI: 0.6760\n",
            "Epoch 60/100 - Train Loss: 0.9841, Val CI: 0.7005\n",
            "Epoch 70/100 - Train Loss: 1.0668, Val CI: 0.6915\n",
            "Epoch 80/100 - Train Loss: 1.0180, Val CI: 0.6755\n",
            "Epoch 90/100 - Train Loss: 1.0720, Val CI: 0.6639\n",
            "Epoch 100/100 - Train Loss: 0.9303, Val CI: 0.6687\n",
            "Finished config: Val CI = 0.7088\n",
            "\n",
            "Training with layers=[32], dropout=0.2, lr=0.001, weight_decay=0.0\n",
            "Epoch 10/100 - Train Loss: 2.1709, Val CI: 0.6243\n",
            "Epoch 20/100 - Train Loss: 1.6069, Val CI: 0.5945\n",
            "Epoch 30/100 - Train Loss: 1.6529, Val CI: 0.6245\n",
            "Epoch 40/100 - Train Loss: 1.2190, Val CI: 0.6620\n",
            "Epoch 50/100 - Train Loss: 1.1724, Val CI: 0.6264\n",
            "Epoch 60/100 - Train Loss: 1.1057, Val CI: 0.6503\n",
            "Epoch 70/100 - Train Loss: 0.9658, Val CI: 0.6426\n",
            "Epoch 80/100 - Train Loss: 1.0589, Val CI: 0.6488\n",
            "Epoch 90/100 - Train Loss: 0.9957, Val CI: 0.6518\n",
            "Epoch 100/100 - Train Loss: 1.0428, Val CI: 0.6706\n",
            "Finished config: Val CI = 0.6706\n",
            "\n",
            "Training with layers=[32], dropout=0.2, lr=0.001, weight_decay=0.0001\n",
            "Epoch 10/100 - Train Loss: 2.1760, Val CI: 0.6069\n",
            "Epoch 20/100 - Train Loss: 1.6785, Val CI: 0.6092\n",
            "Epoch 30/100 - Train Loss: 1.4056, Val CI: 0.6152\n",
            "Epoch 40/100 - Train Loss: 1.4684, Val CI: 0.6457\n",
            "Epoch 50/100 - Train Loss: 1.2403, Val CI: 0.6365\n",
            "Epoch 60/100 - Train Loss: 1.1891, Val CI: 0.6597\n",
            "Epoch 70/100 - Train Loss: 1.0435, Val CI: 0.6573\n",
            "Epoch 80/100 - Train Loss: 1.1312, Val CI: 0.6586\n",
            "Epoch 90/100 - Train Loss: 0.9819, Val CI: 0.6550\n",
            "Epoch 100/100 - Train Loss: 1.0608, Val CI: 0.6633\n",
            "Finished config: Val CI = 0.6780\n",
            "\n",
            "Training with layers=[32], dropout=0.2, lr=0.001, weight_decay=0.001\n",
            "Epoch 10/100 - Train Loss: 2.1953, Val CI: 0.6387\n",
            "Epoch 20/100 - Train Loss: 1.5477, Val CI: 0.6369\n",
            "Epoch 30/100 - Train Loss: 1.6228, Val CI: 0.6236\n",
            "Epoch 40/100 - Train Loss: 1.2773, Val CI: 0.6657\n",
            "Epoch 50/100 - Train Loss: 1.1555, Val CI: 0.6564\n",
            "Epoch 60/100 - Train Loss: 1.0700, Val CI: 0.6641\n",
            "Epoch 70/100 - Train Loss: 1.0739, Val CI: 0.6448\n",
            "Epoch 80/100 - Train Loss: 0.9899, Val CI: 0.6624\n",
            "Epoch 90/100 - Train Loss: 0.9115, Val CI: 0.6311\n",
            "Epoch 100/100 - Train Loss: 0.9162, Val CI: 0.6656\n",
            "Finished config: Val CI = 0.6810\n",
            "\n",
            "Training with layers=[32], dropout=0.2, lr=0.01, weight_decay=0.0\n",
            "Epoch 10/100 - Train Loss: 2.5071, Val CI: 0.6317\n",
            "Epoch 20/100 - Train Loss: 2.0996, Val CI: 0.6603\n",
            "Epoch 30/100 - Train Loss: 1.6699, Val CI: 0.6502\n",
            "Epoch 40/100 - Train Loss: 1.8912, Val CI: 0.6660\n",
            "Epoch 50/100 - Train Loss: 1.7588, Val CI: 0.6690\n",
            "Epoch 60/100 - Train Loss: 1.8204, Val CI: 0.6534\n",
            "Epoch 70/100 - Train Loss: 1.4825, Val CI: 0.6258\n",
            "Epoch 80/100 - Train Loss: 1.5416, Val CI: 0.6707\n",
            "Epoch 90/100 - Train Loss: 1.5027, Val CI: 0.6597\n",
            "Epoch 100/100 - Train Loss: 1.8301, Val CI: 0.6412\n",
            "Finished config: Val CI = 0.6960\n",
            "\n",
            "Training with layers=[32], dropout=0.2, lr=0.01, weight_decay=0.0001\n",
            "Epoch 10/100 - Train Loss: 2.4926, Val CI: 0.6224\n",
            "Epoch 20/100 - Train Loss: 2.0006, Val CI: 0.6247\n",
            "Epoch 30/100 - Train Loss: 1.6376, Val CI: 0.6091\n",
            "Epoch 40/100 - Train Loss: 1.4386, Val CI: 0.6505\n",
            "Epoch 50/100 - Train Loss: 1.3884, Val CI: 0.6552\n",
            "Epoch 60/100 - Train Loss: 1.3649, Val CI: 0.6618\n",
            "Epoch 70/100 - Train Loss: 1.1742, Val CI: 0.6655\n",
            "Epoch 80/100 - Train Loss: 1.3251, Val CI: 0.6656\n",
            "Epoch 90/100 - Train Loss: 1.5199, Val CI: 0.6483\n",
            "Epoch 100/100 - Train Loss: 1.1726, Val CI: 0.6734\n",
            "Finished config: Val CI = 0.6830\n",
            "\n",
            "Training with layers=[32], dropout=0.2, lr=0.01, weight_decay=0.001\n",
            "Epoch 10/100 - Train Loss: 2.5031, Val CI: 0.6398\n",
            "Epoch 20/100 - Train Loss: 1.9535, Val CI: 0.6662\n",
            "Epoch 30/100 - Train Loss: 1.5803, Val CI: 0.6926\n",
            "Epoch 40/100 - Train Loss: 1.4325, Val CI: 0.6640\n",
            "Epoch 50/100 - Train Loss: 1.3255, Val CI: 0.6775\n",
            "Epoch 60/100 - Train Loss: 1.2111, Val CI: 0.6531\n",
            "Epoch 70/100 - Train Loss: 1.2242, Val CI: 0.6666\n",
            "Epoch 80/100 - Train Loss: 1.2249, Val CI: 0.6518\n",
            "Epoch 90/100 - Train Loss: 1.1482, Val CI: 0.6655\n",
            "Epoch 100/100 - Train Loss: 1.1557, Val CI: 0.6478\n",
            "Finished config: Val CI = 0.6954\n",
            "\n",
            "Training with layers=[32], dropout=0.5, lr=0.001, weight_decay=0.0\n",
            "Epoch 10/100 - Train Loss: 2.7261, Val CI: 0.6520\n",
            "Epoch 20/100 - Train Loss: 2.3648, Val CI: 0.6603\n",
            "Epoch 30/100 - Train Loss: 2.1179, Val CI: 0.6479\n",
            "Epoch 40/100 - Train Loss: 1.8660, Val CI: 0.6242\n",
            "Epoch 50/100 - Train Loss: 1.7276, Val CI: 0.6692\n",
            "Epoch 60/100 - Train Loss: 1.6693, Val CI: 0.6476\n",
            "Epoch 70/100 - Train Loss: 1.6525, Val CI: 0.6745\n",
            "Epoch 80/100 - Train Loss: 1.5012, Val CI: 0.6647\n",
            "Epoch 90/100 - Train Loss: 1.5741, Val CI: 0.6575\n",
            "Epoch 100/100 - Train Loss: 1.3251, Val CI: 0.6701\n",
            "Finished config: Val CI = 0.6909\n",
            "\n",
            "Training with layers=[32], dropout=0.5, lr=0.001, weight_decay=0.0001\n",
            "Epoch 10/100 - Train Loss: 2.6676, Val CI: 0.6202\n",
            "Epoch 20/100 - Train Loss: 2.2405, Val CI: 0.6195\n",
            "Epoch 30/100 - Train Loss: 2.1528, Val CI: 0.5982\n",
            "Epoch 40/100 - Train Loss: 1.8609, Val CI: 0.6637\n",
            "Epoch 50/100 - Train Loss: 1.6035, Val CI: 0.6540\n",
            "Epoch 60/100 - Train Loss: 1.5050, Val CI: 0.6551\n",
            "Epoch 70/100 - Train Loss: 1.4844, Val CI: 0.6178\n",
            "Epoch 80/100 - Train Loss: 1.4523, Val CI: 0.6546\n",
            "Epoch 90/100 - Train Loss: 1.4606, Val CI: 0.6476\n",
            "Epoch 100/100 - Train Loss: 1.4370, Val CI: 0.6509\n",
            "Finished config: Val CI = 0.6766\n",
            "\n",
            "Training with layers=[32], dropout=0.5, lr=0.001, weight_decay=0.001\n",
            "Epoch 10/100 - Train Loss: 2.4732, Val CI: 0.6474\n",
            "Epoch 20/100 - Train Loss: 2.1312, Val CI: 0.6389\n",
            "Epoch 30/100 - Train Loss: 1.8171, Val CI: 0.6297\n",
            "Epoch 40/100 - Train Loss: 1.6793, Val CI: 0.6187\n",
            "Epoch 50/100 - Train Loss: 1.6123, Val CI: 0.6629\n",
            "Epoch 60/100 - Train Loss: 1.4805, Val CI: 0.6609\n",
            "Epoch 70/100 - Train Loss: 1.4011, Val CI: 0.6653\n",
            "Epoch 80/100 - Train Loss: 1.3116, Val CI: 0.6795\n",
            "Epoch 90/100 - Train Loss: 1.2314, Val CI: 0.6581\n",
            "Epoch 100/100 - Train Loss: 1.2320, Val CI: 0.6552\n",
            "Finished config: Val CI = 0.6817\n",
            "\n",
            "Training with layers=[32], dropout=0.5, lr=0.01, weight_decay=0.0\n",
            "Epoch 10/100 - Train Loss: 3.1795, Val CI: 0.6168\n",
            "Epoch 20/100 - Train Loss: 2.6945, Val CI: 0.6177\n",
            "Epoch 30/100 - Train Loss: 2.6461, Val CI: 0.6009\n",
            "Epoch 40/100 - Train Loss: 2.4714, Val CI: 0.6157\n",
            "Epoch 50/100 - Train Loss: 2.3030, Val CI: 0.6618\n",
            "Epoch 60/100 - Train Loss: 2.2212, Val CI: 0.6608\n",
            "Epoch 70/100 - Train Loss: 2.1353, Val CI: 0.6612\n",
            "Epoch 80/100 - Train Loss: 2.0449, Val CI: 0.6784\n",
            "Epoch 90/100 - Train Loss: 2.0512, Val CI: 0.6657\n",
            "Epoch 100/100 - Train Loss: 2.1275, Val CI: 0.6813\n",
            "Finished config: Val CI = 0.6903\n",
            "\n",
            "Training with layers=[32], dropout=0.5, lr=0.01, weight_decay=0.0001\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 10/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 20/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 30/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 40/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 50/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 60/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 70/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 80/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 90/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 100/100 - Train Loss: nan, Val CI: -inf\n",
            "Finished config: Val CI = -inf\n",
            "\n",
            "Training with layers=[32], dropout=0.5, lr=0.01, weight_decay=0.001\n",
            "Epoch 10/100 - Train Loss: 2.8933, Val CI: 0.6412\n",
            "Epoch 20/100 - Train Loss: 2.4323, Val CI: 0.6957\n",
            "Epoch 30/100 - Train Loss: 2.0577, Val CI: 0.6658\n",
            "Epoch 40/100 - Train Loss: 1.8470, Val CI: 0.6808\n",
            "Epoch 50/100 - Train Loss: 1.7414, Val CI: 0.6642\n",
            "Epoch 60/100 - Train Loss: 1.6355, Val CI: 0.6666\n",
            "Epoch 70/100 - Train Loss: 1.5695, Val CI: 0.6517\n",
            "Epoch 80/100 - Train Loss: 1.4047, Val CI: 0.6522\n",
            "Epoch 90/100 - Train Loss: 1.4512, Val CI: 0.6558\n",
            "Epoch 100/100 - Train Loss: 1.5506, Val CI: 0.6616\n",
            "Finished config: Val CI = 0.6957\n",
            "\n",
            "Training with layers=[64], dropout=0.0, lr=0.001, weight_decay=0.0\n",
            "Epoch 10/100 - Train Loss: 1.7458, Val CI: 0.6278\n",
            "Epoch 20/100 - Train Loss: 1.7386, Val CI: 0.5892\n",
            "Epoch 30/100 - Train Loss: 1.1747, Val CI: 0.6527\n",
            "Epoch 40/100 - Train Loss: 1.1474, Val CI: 0.6289\n",
            "Epoch 50/100 - Train Loss: 1.2316, Val CI: 0.6304\n",
            "Epoch 60/100 - Train Loss: 1.0985, Val CI: 0.6106\n",
            "Epoch 70/100 - Train Loss: 1.1175, Val CI: 0.6527\n",
            "Epoch 80/100 - Train Loss: 1.0877, Val CI: 0.6422\n",
            "Epoch 90/100 - Train Loss: 1.0376, Val CI: 0.6595\n",
            "Epoch 100/100 - Train Loss: 0.9094, Val CI: 0.6206\n",
            "Finished config: Val CI = 0.6742\n",
            "\n",
            "Training with layers=[64], dropout=0.0, lr=0.001, weight_decay=0.0001\n",
            "Epoch 10/100 - Train Loss: 2.1756, Val CI: 0.6357\n",
            "Epoch 20/100 - Train Loss: 1.5827, Val CI: 0.6210\n",
            "Epoch 30/100 - Train Loss: 1.4101, Val CI: 0.6333\n",
            "Epoch 40/100 - Train Loss: 1.4475, Val CI: 0.6586\n",
            "Epoch 50/100 - Train Loss: 1.3279, Val CI: 0.6476\n",
            "Epoch 60/100 - Train Loss: 1.0709, Val CI: 0.6566\n",
            "Epoch 70/100 - Train Loss: 1.0468, Val CI: 0.6359\n",
            "Epoch 80/100 - Train Loss: 0.8341, Val CI: 0.6084\n",
            "Epoch 90/100 - Train Loss: 0.9942, Val CI: 0.6548\n",
            "Epoch 100/100 - Train Loss: 1.1487, Val CI: 0.6190\n",
            "Finished config: Val CI = 0.6686\n",
            "\n",
            "Training with layers=[64], dropout=0.0, lr=0.001, weight_decay=0.001\n",
            "Epoch 10/100 - Train Loss: 2.0343, Val CI: 0.6545\n",
            "Epoch 20/100 - Train Loss: 1.7710, Val CI: 0.6175\n",
            "Epoch 30/100 - Train Loss: 1.1340, Val CI: 0.6220\n",
            "Epoch 40/100 - Train Loss: 1.3206, Val CI: 0.6335\n",
            "Epoch 50/100 - Train Loss: 0.9369, Val CI: 0.6732\n",
            "Epoch 60/100 - Train Loss: 0.8451, Val CI: 0.6643\n",
            "Epoch 70/100 - Train Loss: 0.9769, Val CI: 0.6753\n",
            "Epoch 80/100 - Train Loss: 0.9509, Val CI: 0.6336\n",
            "Epoch 90/100 - Train Loss: 0.7186, Val CI: 0.6551\n",
            "Epoch 100/100 - Train Loss: 1.0756, Val CI: 0.6361\n",
            "Finished config: Val CI = 0.6804\n",
            "\n",
            "Training with layers=[64], dropout=0.0, lr=0.01, weight_decay=0.0\n",
            "Epoch 10/100 - Train Loss: 2.5515, Val CI: 0.6238\n",
            "Epoch 20/100 - Train Loss: 1.8083, Val CI: 0.6638\n",
            "Epoch 30/100 - Train Loss: 1.3974, Val CI: 0.6483\n",
            "Epoch 40/100 - Train Loss: 1.1731, Val CI: 0.6501\n",
            "Epoch 50/100 - Train Loss: 1.4542, Val CI: 0.6597\n",
            "Epoch 60/100 - Train Loss: 1.0866, Val CI: 0.6176\n",
            "Epoch 70/100 - Train Loss: 1.0519, Val CI: 0.6417\n",
            "Epoch 80/100 - Train Loss: 1.3066, Val CI: 0.6708\n",
            "Epoch 90/100 - Train Loss: 0.8841, Val CI: 0.6728\n",
            "Epoch 100/100 - Train Loss: 1.0094, Val CI: 0.6839\n",
            "Finished config: Val CI = 0.6900\n",
            "\n",
            "Training with layers=[64], dropout=0.0, lr=0.01, weight_decay=0.0001\n",
            "Epoch 10/100 - Train Loss: 2.3144, Val CI: 0.5673\n",
            "Epoch 20/100 - Train Loss: 1.7599, Val CI: 0.6692\n",
            "Epoch 30/100 - Train Loss: 1.4289, Val CI: 0.6286\n",
            "Epoch 40/100 - Train Loss: 1.2272, Val CI: 0.6580\n",
            "Epoch 50/100 - Train Loss: 1.1839, Val CI: 0.6662\n",
            "Epoch 60/100 - Train Loss: 1.2792, Val CI: 0.6783\n",
            "Epoch 70/100 - Train Loss: 1.1228, Val CI: 0.6645\n",
            "Epoch 80/100 - Train Loss: 1.0413, Val CI: 0.6715\n",
            "Epoch 90/100 - Train Loss: 1.0495, Val CI: 0.6741\n",
            "Epoch 100/100 - Train Loss: 0.7872, Val CI: 0.6703\n",
            "Finished config: Val CI = 0.6911\n",
            "\n",
            "Training with layers=[64], dropout=0.0, lr=0.01, weight_decay=0.001\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 10/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 20/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 30/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 40/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 50/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 60/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 70/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 80/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 90/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 100/100 - Train Loss: nan, Val CI: -inf\n",
            "Finished config: Val CI = -inf\n",
            "\n",
            "Training with layers=[64], dropout=0.2, lr=0.001, weight_decay=0.0\n",
            "Epoch 10/100 - Train Loss: 2.2140, Val CI: 0.6304\n",
            "Epoch 20/100 - Train Loss: 1.6816, Val CI: 0.6328\n",
            "Epoch 30/100 - Train Loss: 1.8298, Val CI: 0.6577\n",
            "Epoch 40/100 - Train Loss: 1.4589, Val CI: 0.6336\n",
            "Epoch 50/100 - Train Loss: 1.2431, Val CI: 0.5485\n",
            "Epoch 60/100 - Train Loss: 1.1374, Val CI: 0.6437\n",
            "Epoch 70/100 - Train Loss: 1.1217, Val CI: 0.6322\n",
            "Epoch 80/100 - Train Loss: 1.2810, Val CI: 0.6367\n",
            "Epoch 90/100 - Train Loss: 1.1023, Val CI: 0.6374\n",
            "Epoch 100/100 - Train Loss: 1.0360, Val CI: 0.6485\n",
            "Finished config: Val CI = 0.6671\n",
            "\n",
            "Training with layers=[64], dropout=0.2, lr=0.001, weight_decay=0.0001\n",
            "Epoch 10/100 - Train Loss: 2.3828, Val CI: 0.6670\n",
            "Epoch 20/100 - Train Loss: 1.7009, Val CI: 0.6600\n",
            "Epoch 30/100 - Train Loss: 1.5477, Val CI: 0.6684\n",
            "Epoch 40/100 - Train Loss: 1.4255, Val CI: 0.6569\n",
            "Epoch 50/100 - Train Loss: 1.3659, Val CI: 0.6524\n",
            "Epoch 60/100 - Train Loss: 1.1599, Val CI: 0.6436\n",
            "Epoch 70/100 - Train Loss: 1.1059, Val CI: 0.6538\n",
            "Epoch 80/100 - Train Loss: 1.2495, Val CI: 0.6389\n",
            "Epoch 90/100 - Train Loss: 0.9967, Val CI: 0.6564\n",
            "Epoch 100/100 - Train Loss: 1.1219, Val CI: 0.6362\n",
            "Finished config: Val CI = 0.6762\n",
            "\n",
            "Training with layers=[64], dropout=0.2, lr=0.001, weight_decay=0.001\n",
            "Epoch 10/100 - Train Loss: 2.0436, Val CI: 0.5978\n",
            "Epoch 20/100 - Train Loss: 1.5624, Val CI: 0.6510\n",
            "Epoch 30/100 - Train Loss: 1.5586, Val CI: 0.6658\n",
            "Epoch 40/100 - Train Loss: 1.2666, Val CI: 0.6413\n",
            "Epoch 50/100 - Train Loss: 1.1444, Val CI: 0.6463\n",
            "Epoch 60/100 - Train Loss: 1.0500, Val CI: 0.6489\n",
            "Epoch 70/100 - Train Loss: 1.1733, Val CI: 0.6775\n",
            "Epoch 80/100 - Train Loss: 1.1007, Val CI: 0.6596\n",
            "Epoch 90/100 - Train Loss: 1.0101, Val CI: 0.6439\n",
            "Epoch 100/100 - Train Loss: 1.0500, Val CI: 0.6609\n",
            "Finished config: Val CI = 0.6775\n",
            "\n",
            "Training with layers=[64], dropout=0.2, lr=0.01, weight_decay=0.0\n",
            "Epoch 10/100 - Train Loss: 2.4700, Val CI: 0.6336\n",
            "Epoch 20/100 - Train Loss: 2.0127, Val CI: 0.5737\n",
            "Epoch 30/100 - Train Loss: 1.9342, Val CI: 0.5860\n",
            "Epoch 40/100 - Train Loss: 1.9102, Val CI: 0.5983\n",
            "Epoch 50/100 - Train Loss: 1.7443, Val CI: 0.6324\n",
            "Epoch 60/100 - Train Loss: 1.8968, Val CI: 0.6636\n",
            "Epoch 70/100 - Train Loss: 1.7533, Val CI: 0.6452\n",
            "Epoch 80/100 - Train Loss: 1.4621, Val CI: 0.6460\n",
            "Epoch 90/100 - Train Loss: 1.5164, Val CI: 0.6727\n",
            "Epoch 100/100 - Train Loss: 1.2889, Val CI: 0.6334\n",
            "Finished config: Val CI = 0.6728\n",
            "\n",
            "Training with layers=[64], dropout=0.2, lr=0.01, weight_decay=0.0001\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 10/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 20/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 30/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 40/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 50/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 60/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 70/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 80/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 90/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 100/100 - Train Loss: nan, Val CI: -inf\n",
            "Finished config: Val CI = -inf\n",
            "\n",
            "Training with layers=[64], dropout=0.2, lr=0.01, weight_decay=0.001\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 10/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 20/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 30/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 40/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 50/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 60/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 70/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 80/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 90/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 100/100 - Train Loss: nan, Val CI: -inf\n",
            "Finished config: Val CI = -inf\n",
            "\n",
            "Training with layers=[64], dropout=0.5, lr=0.001, weight_decay=0.0\n",
            "Epoch 10/100 - Train Loss: 2.5093, Val CI: 0.6398\n",
            "Epoch 20/100 - Train Loss: 1.9934, Val CI: 0.6610\n",
            "Epoch 30/100 - Train Loss: 1.7088, Val CI: 0.6619\n",
            "Epoch 40/100 - Train Loss: 1.7031, Val CI: 0.6559\n",
            "Epoch 50/100 - Train Loss: 1.6204, Val CI: 0.6506\n",
            "Epoch 60/100 - Train Loss: 1.5042, Val CI: 0.6538\n",
            "Epoch 70/100 - Train Loss: 1.5286, Val CI: 0.6562\n",
            "Epoch 80/100 - Train Loss: 1.5399, Val CI: 0.6583\n",
            "Epoch 90/100 - Train Loss: 1.4651, Val CI: 0.6679\n",
            "Epoch 100/100 - Train Loss: 1.2949, Val CI: 0.6638\n",
            "Finished config: Val CI = 0.6852\n",
            "\n",
            "Training with layers=[64], dropout=0.5, lr=0.001, weight_decay=0.0001\n",
            "Epoch 10/100 - Train Loss: 2.8845, Val CI: 0.5788\n",
            "Epoch 20/100 - Train Loss: 2.0896, Val CI: 0.6451\n",
            "Epoch 30/100 - Train Loss: 1.8416, Val CI: 0.6398\n",
            "Epoch 40/100 - Train Loss: 1.8036, Val CI: 0.6260\n",
            "Epoch 50/100 - Train Loss: 1.6155, Val CI: 0.6690\n",
            "Epoch 60/100 - Train Loss: 1.5230, Val CI: 0.6428\n",
            "Epoch 70/100 - Train Loss: 1.4614, Val CI: 0.6632\n",
            "Epoch 80/100 - Train Loss: 1.5461, Val CI: 0.6265\n",
            "Epoch 90/100 - Train Loss: 1.3282, Val CI: 0.6680\n",
            "Epoch 100/100 - Train Loss: 1.3042, Val CI: 0.6540\n",
            "Finished config: Val CI = 0.6786\n",
            "\n",
            "Training with layers=[64], dropout=0.5, lr=0.001, weight_decay=0.001\n",
            "Epoch 10/100 - Train Loss: 2.5929, Val CI: 0.5629\n",
            "Epoch 20/100 - Train Loss: 2.1436, Val CI: 0.6510\n",
            "Epoch 30/100 - Train Loss: 1.9886, Val CI: 0.6184\n",
            "Epoch 40/100 - Train Loss: 1.6497, Val CI: 0.6476\n",
            "Epoch 50/100 - Train Loss: 1.4961, Val CI: 0.6353\n",
            "Epoch 60/100 - Train Loss: 1.5172, Val CI: 0.6716\n",
            "Epoch 70/100 - Train Loss: 1.3696, Val CI: 0.6771\n",
            "Epoch 80/100 - Train Loss: 1.2402, Val CI: 0.6600\n",
            "Epoch 90/100 - Train Loss: 1.0952, Val CI: 0.6627\n",
            "Epoch 100/100 - Train Loss: 1.1411, Val CI: 0.6576\n",
            "Finished config: Val CI = 0.6845\n",
            "\n",
            "Training with layers=[64], dropout=0.5, lr=0.01, weight_decay=0.0\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Epoch 10/100 - Train Loss: nan, Val CI: -inf\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n",
            "Warning: NaN predictions detected, returning -inf for concordance index\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsurv.loss.cox import neg_partial_log_likelihood\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"Ties in event time detected; using efron's method to handle ties.\")\n",
        "\n",
        "# Define a Tee class for logging output to both console and file\n",
        "class Tee:\n",
        "    def __init__(self, *files):\n",
        "        self.files = files\n",
        "    def write(self, data):\n",
        "        for f in self.files:\n",
        "            f.write(data)\n",
        "    def flush(self):\n",
        "        for f in self.files:\n",
        "            f.flush()\n",
        "\n",
        "# Define a custom MLP model for DeepSurv\n",
        "class DeepSurvMLP(nn.Module):\n",
        "    def __init__(self, in_features, hidden_layers, dropout=0.0, activation=nn.ReLU()):\n",
        "        super(DeepSurvMLP, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.BatchNorm1d(in_features))\n",
        "        current_dim = in_features\n",
        "        for units in hidden_layers:\n",
        "            layers.append(nn.Linear(current_dim, units))\n",
        "            layers.append(activation)\n",
        "            if dropout > 0:\n",
        "                layers.append(nn.Dropout(dropout))\n",
        "            current_dim = units\n",
        "        layers.append(nn.Linear(current_dim, 1))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Define a PyTorch Dataset for survival data\n",
        "class SurvivalDataset(Dataset):\n",
        "    def __init__(self, features, time_vals, events):\n",
        "        self.x = torch.tensor(features, dtype=torch.float32)\n",
        "        self.time = torch.tensor(time_vals, dtype=torch.float32)\n",
        "        self.event = torch.tensor(events, dtype=torch.bool)\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.time[idx], self.event[idx]\n",
        "\n",
        "def train_model(model, optimizer, dataloader, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for x, time_vals, events in dataloader:\n",
        "        x = x.to(device)\n",
        "        time_vals = time_vals.to(device)\n",
        "        events = events.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x)\n",
        "        loss = neg_partial_log_likelihood(outputs, events, time_vals, reduction='mean')\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "    return running_loss / len(dataloader.dataset)\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_time = []\n",
        "    all_event = []\n",
        "    with torch.no_grad():\n",
        "        for x, time_vals, events in dataloader:\n",
        "            x = x.to(device)\n",
        "            preds = model(x)\n",
        "            all_preds.append(preds.cpu().numpy().flatten())\n",
        "            all_time.append(time_vals.cpu().numpy())\n",
        "            all_event.append(events.cpu().numpy())\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    if np.isnan(all_preds).any():\n",
        "        print(\"Warning: NaN predictions detected, returning -inf for concordance index\")\n",
        "        return -np.inf\n",
        "    all_time = np.concatenate(all_time)\n",
        "    all_event = np.concatenate(all_event)\n",
        "    ci = concordance_index_censored(all_event.astype(bool), all_time, all_preds)[0]\n",
        "    return ci\n",
        "\n",
        "def main():\n",
        "    # Capture the original stdout\n",
        "    original_stdout = sys.stdout\n",
        "    log_path = \"/content/drive/MyDrive/deepsurv_training_log.txt\"\n",
        "\n",
        "    # Open log file with context, and use Tee to write to both original_stdout and file\n",
        "    with open(log_path, \"w\") as log_file:\n",
        "        sys.stdout = Tee(original_stdout, log_file)\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        train_df = pd.read_csv(\"/content/drive/MyDrive/affyTrain.csv\")\n",
        "        valid_df = pd.read_csv(\"/content/drive/MyDrive/affyValidation.csv\")\n",
        "\n",
        "        binary_columns = ['Adjuvant Chemo', 'IS_MALE']\n",
        "        for col in binary_columns:\n",
        "            if col in train_df.columns:\n",
        "                train_df[col] = train_df[col].astype(int)\n",
        "            if col in valid_df.columns:\n",
        "                valid_df[col] = valid_df[col].astype(int)\n",
        "\n",
        "        survival_cols = ['OS_STATUS', 'OS_MONTHS']\n",
        "        feature_cols = [col for col in train_df.columns if col not in survival_cols]\n",
        "\n",
        "        X_train = train_df[feature_cols].values.astype(np.float32)\n",
        "        y_train_time = train_df['OS_MONTHS'].values.astype(np.float32)\n",
        "        y_train_event = train_df['OS_STATUS'].values.astype(np.float32)\n",
        "\n",
        "        X_valid = valid_df[feature_cols].values.astype(np.float32)\n",
        "        y_valid_time = valid_df['OS_MONTHS'].values.astype(np.float32)\n",
        "        y_valid_event = valid_df['OS_STATUS'].values.astype(np.float32)\n",
        "\n",
        "        train_dataset = SurvivalDataset(X_train, y_train_time, y_train_event)\n",
        "        valid_dataset = SurvivalDataset(X_valid, y_valid_time, y_valid_event)\n",
        "\n",
        "        batch_size = 32\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        hidden_layer_configs = [\n",
        "            [32],\n",
        "            [64],\n",
        "            [32, 16],\n",
        "            [64, 32]\n",
        "        ]\n",
        "        dropout_rates = [0.0, 0.2, 0.5]\n",
        "        learning_rates = [0.001, 0.01]\n",
        "        weight_decays = [0.0, 1e-4, 1e-3]\n",
        "\n",
        "        num_epochs = 100\n",
        "        best_ci = -np.inf\n",
        "        best_hyperparams = None\n",
        "        best_model_state = None\n",
        "        results = []\n",
        "\n",
        "        for layers in hidden_layer_configs:\n",
        "            for dropout in dropout_rates:\n",
        "                for lr in learning_rates:\n",
        "                    for wd in weight_decays:\n",
        "                        print(f\"Training with layers={layers}, dropout={dropout}, lr={lr}, weight_decay={wd}\")\n",
        "                        model = DeepSurvMLP(in_features=X_train.shape[1],\n",
        "                                            hidden_layers=layers,\n",
        "                                            dropout=dropout,\n",
        "                                            activation=nn.ReLU()).to(device)\n",
        "                        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "                        best_epoch_ci = -np.inf\n",
        "                        for epoch in range(num_epochs):\n",
        "                            train_loss = train_model(model, optimizer, train_loader, device)\n",
        "                            val_ci = evaluate_model(model, valid_loader, device)\n",
        "                            if (epoch + 1) % 10 == 0:\n",
        "                                print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val CI: {val_ci:.4f}\")\n",
        "                            if val_ci > best_epoch_ci:\n",
        "                                best_epoch_ci = val_ci\n",
        "                        results.append({\n",
        "                            'layers': layers,\n",
        "                            'dropout': dropout,\n",
        "                            'learning_rate': lr,\n",
        "                            'weight_decay': wd,\n",
        "                            'val_ci': best_epoch_ci\n",
        "                        })\n",
        "                        print(f\"Finished config: Val CI = {best_epoch_ci:.4f}\\n\")\n",
        "                        if best_epoch_ci > best_ci:\n",
        "                            best_ci = best_epoch_ci\n",
        "                            best_hyperparams = {\n",
        "                                'layers': layers,\n",
        "                                'dropout': dropout,\n",
        "                                'learning_rate': lr,\n",
        "                                'weight_decay': wd\n",
        "                            }\n",
        "                            best_model_state = model.state_dict()\n",
        "\n",
        "        print(\"Best Hyperparameters:\")\n",
        "        print(best_hyperparams)\n",
        "        print(\"Best Validation CI:\", best_ci)\n",
        "\n",
        "        current_date = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
        "        output_dir = \"/content/drive/MyDrive/deepsurv_results\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        results_df = pd.DataFrame(results)\n",
        "        results_csv_path = os.path.join(output_dir, f\"{current_date}_deepsurv_hyperparam_search_results.csv\")\n",
        "        results_df.to_csv(results_csv_path, index=False)\n",
        "        print(f\"Hyperparameter search results saved to {results_csv_path}\")\n",
        "\n",
        "        best_model_path = os.path.join(output_dir, f\"{current_date}_best_deepsurv_model.pth\")\n",
        "        torch.save(best_model_state, best_model_path)\n",
        "        print(f\"Best model saved to {best_model_path}\")\n",
        "\n",
        "        # Flush before exiting the with block\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    # Restore original stdout for subsequent prints to the console\n",
        "    sys.stdout = original_stdout\n",
        "    print(\"Training completed. Check your log file at:\", log_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}